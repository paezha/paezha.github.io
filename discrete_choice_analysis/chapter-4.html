<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 5 Practical specification and estimation | An Introduction to Discrete Choice Analysis</title>
  <meta name="description" content="These notes were created by Antonio Paez as a resource for teaching a graduate discrete choice analysis course (GEOG 738) at McMaster University.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 5 Practical specification and estimation | An Introduction to Discrete Choice Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These notes were created by Antonio Paez as a resource for teaching a graduate discrete choice analysis course (GEOG 738) at McMaster University." />
  <meta name="github-repo" content="paezha/Discrete-Choice-Analysis-with-R" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Practical specification and estimation | An Introduction to Discrete Choice Analysis" />
  
  <meta name="twitter:description" content="These notes were created by Antonio Paez as a resource for teaching a graduate discrete choice analysis course (GEOG 738) at McMaster University." />
  

<meta name="author" content="Antonio Paez">


<meta name="date" content="2019-03-31">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chapter-3.html">
<link rel="next" href="chapter-5.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.8.0.9000/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.42.5/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.42.5/plotly-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#choices-choices-choices"><i class="fa fa-check"></i>Choices, choices, choices</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#price-mechanisms"><i class="fa fa-check"></i>Price Mechanisms</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#plan"><i class="fa fa-check"></i>Plan</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#audience"><i class="fa fa-check"></i>Audience</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#requisites"><i class="fa fa-check"></i>Requisites</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="preliminaries-installing-r-and-rstudio.html"><a href="preliminaries-installing-r-and-rstudio.html"><i class="fa fa-check"></i><b>1</b> Preliminaries: Installing R and RStudio</a><ul>
<li class="chapter" data-level="1.1" data-path="preliminaries-installing-r-and-rstudio.html"><a href="preliminaries-installing-r-and-rstudio.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="preliminaries-installing-r-and-rstudio.html"><a href="preliminaries-installing-r-and-rstudio.html#learning-objectives"><i class="fa fa-check"></i><b>1.2</b> Learning Objectives</a></li>
<li class="chapter" data-level="1.3" data-path="preliminaries-installing-r-and-rstudio.html"><a href="preliminaries-installing-r-and-rstudio.html#r-the-open-statistical-computing-project"><i class="fa fa-check"></i><b>1.3</b> R: The Open Statistical Computing Project</a><ul>
<li class="chapter" data-level="1.3.1" data-path="preliminaries-installing-r-and-rstudio.html"><a href="preliminaries-installing-r-and-rstudio.html#what-is-r"><i class="fa fa-check"></i><b>1.3.1</b> What is R?</a></li>
<li class="chapter" data-level="1.3.2" data-path="preliminaries-installing-r-and-rstudio.html"><a href="preliminaries-installing-r-and-rstudio.html#the-rstudio-ide"><i class="fa fa-check"></i><b>1.3.2</b> The RStudio IDE</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="preliminaries-installing-r-and-rstudio.html"><a href="preliminaries-installing-r-and-rstudio.html#packages-in-r"><i class="fa fa-check"></i><b>1.4</b> Packages in R</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter-1.html"><a href="chapter-1.html"><i class="fa fa-check"></i><b>2</b> Data and stuff</a><ul>
<li class="chapter" data-level="2.1" data-path="chapter-1.html"><a href="chapter-1.html#what-are-models"><i class="fa fa-check"></i><b>2.1</b> What are models?</a></li>
<li class="chapter" data-level="2.2" data-path="chapter-1.html"><a href="chapter-1.html#how-to-use-this-note"><i class="fa fa-check"></i><b>2.2</b> How to use this note</a></li>
<li class="chapter" data-level="2.3" data-path="chapter-1.html"><a href="chapter-1.html#learning-objectives-1"><i class="fa fa-check"></i><b>2.3</b> Learning objectives</a></li>
<li class="chapter" data-level="2.4" data-path="chapter-1.html"><a href="chapter-1.html#suggested-readings"><i class="fa fa-check"></i><b>2.4</b> Suggested readings</a></li>
<li class="chapter" data-level="2.5" data-path="chapter-1.html"><a href="chapter-1.html#ways-of-measuring-stuff"><i class="fa fa-check"></i><b>2.5</b> Ways of measuring stuff</a><ul>
<li class="chapter" data-level="2.5.1" data-path="chapter-1.html"><a href="chapter-1.html#categorical"><i class="fa fa-check"></i><b>2.5.1</b> Categorical</a></li>
<li class="chapter" data-level="2.5.2" data-path="chapter-1.html"><a href="chapter-1.html#quantitative"><i class="fa fa-check"></i><b>2.5.2</b> Quantitative</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="chapter-1.html"><a href="chapter-1.html#importing-data"><i class="fa fa-check"></i><b>2.6</b> Importing data</a></li>
<li class="chapter" data-level="2.7" data-path="chapter-1.html"><a href="chapter-1.html#data-classes-in-r"><i class="fa fa-check"></i><b>2.7</b> Data Classes in R</a></li>
<li class="chapter" data-level="2.8" data-path="chapter-1.html"><a href="chapter-1.html#more-on-indexing-and-data-manipulation"><i class="fa fa-check"></i><b>2.8</b> More on indexing and data manipulation</a></li>
<li class="chapter" data-level="2.9" data-path="chapter-1.html"><a href="chapter-1.html#visualization"><i class="fa fa-check"></i><b>2.9</b> Visualization</a></li>
<li class="chapter" data-level="2.10" data-path="chapter-1.html"><a href="chapter-1.html#exercise"><i class="fa fa-check"></i><b>2.10</b> Exercise</a><ul>
<li class="chapter" data-level="2.10.1" data-path="chapter-1.html"><a href="chapter-1.html#questions"><i class="fa fa-check"></i><b>2.10.1</b> Questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter-2.html"><a href="chapter-2.html"><i class="fa fa-check"></i><b>3</b> Fundamental concepts</a><ul>
<li class="chapter" data-level="3.1" data-path="chapter-2.html"><a href="chapter-2.html#why-modelling-choices"><i class="fa fa-check"></i><b>3.1</b> Why modelling choices?</a></li>
<li class="chapter" data-level="3.2" data-path="chapter-2.html"><a href="chapter-2.html#how-to-use-this-note-1"><i class="fa fa-check"></i><b>3.2</b> How to use this note</a></li>
<li class="chapter" data-level="3.3" data-path="chapter-2.html"><a href="chapter-2.html#learning-objectives-2"><i class="fa fa-check"></i><b>3.3</b> Learning objectives</a></li>
<li class="chapter" data-level="3.4" data-path="chapter-2.html"><a href="chapter-2.html#suggested-readings-1"><i class="fa fa-check"></i><b>3.4</b> Suggested readings</a></li>
<li class="chapter" data-level="3.5" data-path="chapter-2.html"><a href="chapter-2.html#preliminaries"><i class="fa fa-check"></i><b>3.5</b> Preliminaries</a></li>
<li class="chapter" data-level="3.6" data-path="chapter-2.html"><a href="chapter-2.html#utility-maximization"><i class="fa fa-check"></i><b>3.6</b> Utility maximization</a></li>
<li class="chapter" data-level="3.7" data-path="chapter-2.html"><a href="chapter-2.html#what-about-those-random-terms"><i class="fa fa-check"></i><b>3.7</b> What about those random terms?</a></li>
<li class="chapter" data-level="3.8" data-path="chapter-2.html"><a href="chapter-2.html#probability-distribution-functions-pdfs"><i class="fa fa-check"></i><b>3.8</b> Probability distribution functions (PDFs)</a></li>
<li class="chapter" data-level="3.9" data-path="chapter-2.html"><a href="chapter-2.html#a-simple-random-utility-discrete-choice-model"><i class="fa fa-check"></i><b>3.9</b> A simple random utility discrete choice model</a></li>
<li class="chapter" data-level="3.10" data-path="chapter-2.html"><a href="chapter-2.html#other-choice-mechanisms"><i class="fa fa-check"></i><b>3.10</b> Other choice mechanisms</a></li>
<li class="chapter" data-level="3.11" data-path="chapter-2.html"><a href="chapter-2.html#exercise-1"><i class="fa fa-check"></i><b>3.11</b> Exercise</a><ul>
<li class="chapter" data-level="3.11.1" data-path="chapter-2.html"><a href="chapter-2.html#questions-1"><i class="fa fa-check"></i><b>3.11.1</b> Questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter-3.html"><a href="chapter-3.html"><i class="fa fa-check"></i><b>4</b> Logit</a><ul>
<li class="chapter" data-level="4.1" data-path="chapter-3.html"><a href="chapter-3.html#modelling-choices"><i class="fa fa-check"></i><b>4.1</b> Modelling choices</a></li>
<li class="chapter" data-level="4.2" data-path="chapter-3.html"><a href="chapter-3.html#how-to-use-this-note-2"><i class="fa fa-check"></i><b>4.2</b> How to use this note</a></li>
<li class="chapter" data-level="4.3" data-path="chapter-3.html"><a href="chapter-3.html#learning-objectives-3"><i class="fa fa-check"></i><b>4.3</b> Learning objectives</a></li>
<li class="chapter" data-level="4.4" data-path="chapter-3.html"><a href="chapter-3.html#suggested-readings-2"><i class="fa fa-check"></i><b>4.4</b> Suggested readings</a></li>
<li class="chapter" data-level="4.5" data-path="chapter-3.html"><a href="chapter-3.html#preliminaries-1"><i class="fa fa-check"></i><b>4.5</b> Preliminaries</a></li>
<li class="chapter" data-level="4.6" data-path="chapter-3.html"><a href="chapter-3.html#once-again-those-random-terms"><i class="fa fa-check"></i><b>4.6</b> Once again those random terms</a></li>
<li class="chapter" data-level="4.7" data-path="chapter-3.html"><a href="chapter-3.html#now-about-those-parameters-mu-and-sigma"><i class="fa fa-check"></i><b>4.7</b> Now, about those parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>…</a></li>
<li class="chapter" data-level="4.8" data-path="chapter-3.html"><a href="chapter-3.html#multinomial-logit"><i class="fa fa-check"></i><b>4.8</b> Multinomial logit</a></li>
<li class="chapter" data-level="4.9" data-path="chapter-3.html"><a href="chapter-3.html#properties-of-the-logit-model"><i class="fa fa-check"></i><b>4.9</b> Properties of the logit model</a></li>
<li class="chapter" data-level="4.10" data-path="chapter-3.html"><a href="chapter-3.html#revisiting-the-systematic-utilities"><i class="fa fa-check"></i><b>4.10</b> Revisiting the systematic utilities</a></li>
<li class="chapter" data-level="4.11" data-path="chapter-3.html"><a href="chapter-3.html#exercise-2"><i class="fa fa-check"></i><b>4.11</b> Exercise</a><ul>
<li class="chapter" data-level="4.11.1" data-path="chapter-3.html"><a href="chapter-3.html#questions-2"><i class="fa fa-check"></i><b>4.11.1</b> Questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter-4.html"><a href="chapter-4.html"><i class="fa fa-check"></i><b>5</b> Practical specification and estimation</a><ul>
<li class="chapter" data-level="5.1" data-path="chapter-4.html"><a href="chapter-4.html#theory-and-practice"><i class="fa fa-check"></i><b>5.1</b> Theory and practice</a></li>
<li class="chapter" data-level="5.2" data-path="chapter-4.html"><a href="chapter-4.html#how-to-use-this-note-3"><i class="fa fa-check"></i><b>5.2</b> How to use this note</a></li>
<li class="chapter" data-level="5.3" data-path="chapter-4.html"><a href="chapter-4.html#learning-objectives-4"><i class="fa fa-check"></i><b>5.3</b> Learning objectives</a></li>
<li class="chapter" data-level="5.4" data-path="chapter-4.html"><a href="chapter-4.html#suggested-readings-3"><i class="fa fa-check"></i><b>5.4</b> Suggested readings</a></li>
<li class="chapter" data-level="5.5" data-path="chapter-4.html"><a href="chapter-4.html#preliminaries-2"><i class="fa fa-check"></i><b>5.5</b> Preliminaries</a></li>
<li class="chapter" data-level="5.6" data-path="chapter-4.html"><a href="chapter-4.html#the-anatomy-of-utility-functions"><i class="fa fa-check"></i><b>5.6</b> The anatomy of utility functions</a></li>
<li class="chapter" data-level="5.7" data-path="chapter-4.html"><a href="chapter-4.html#example-specifying-the-utility-functions"><i class="fa fa-check"></i><b>5.7</b> Example: Specifying the utility functions</a></li>
<li class="chapter" data-level="5.8" data-path="chapter-4.html"><a href="chapter-4.html#estimation"><i class="fa fa-check"></i><b>5.8</b> Estimation</a></li>
<li class="chapter" data-level="5.9" data-path="chapter-4.html"><a href="chapter-4.html#example-a-logit-model-of-mode-choice"><i class="fa fa-check"></i><b>5.9</b> Example: A logit model of mode choice</a></li>
<li class="chapter" data-level="5.10" data-path="chapter-4.html"><a href="chapter-4.html#comparing-models-mcfaddens-rho2"><i class="fa fa-check"></i><b>5.10</b> Comparing models: McFadden’s <span class="math inline">\(\rho^2\)</span></a></li>
<li class="chapter" data-level="5.11" data-path="chapter-4.html"><a href="chapter-4.html#comparing-models-the-likelihood-ratio-test"><i class="fa fa-check"></i><b>5.11</b> Comparing models: the likelihood ratio test</a></li>
<li class="chapter" data-level="5.12" data-path="chapter-4.html"><a href="chapter-4.html#exercise-3"><i class="fa fa-check"></i><b>5.12</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter-5.html"><a href="chapter-5.html"><i class="fa fa-check"></i><b>6</b> Behavioral insights from choice models</a><ul>
<li class="chapter" data-level="6.1" data-path="chapter-5.html"><a href="chapter-5.html#inferring-and-forecasting-behavior"><i class="fa fa-check"></i><b>6.1</b> Inferring and forecasting behavior</a></li>
<li class="chapter" data-level="6.2" data-path="chapter-5.html"><a href="chapter-5.html#how-to-use-this-note-4"><i class="fa fa-check"></i><b>6.2</b> How to use this note</a></li>
<li class="chapter" data-level="6.3" data-path="chapter-5.html"><a href="chapter-5.html#learning-objectives-5"><i class="fa fa-check"></i><b>6.3</b> Learning objectives</a></li>
<li class="chapter" data-level="6.4" data-path="chapter-5.html"><a href="chapter-5.html#suggested-readings-4"><i class="fa fa-check"></i><b>6.4</b> Suggested readings</a></li>
<li class="chapter" data-level="6.5" data-path="chapter-5.html"><a href="chapter-5.html#preliminaries-3"><i class="fa fa-check"></i><b>6.5</b> Preliminaries</a></li>
<li class="chapter" data-level="6.6" data-path="chapter-5.html"><a href="chapter-5.html#the-meaning-of-the-coefficients"><i class="fa fa-check"></i><b>6.6</b> The meaning of the coefficients</a></li>
<li class="chapter" data-level="6.7" data-path="chapter-5.html"><a href="chapter-5.html#marginal-effects"><i class="fa fa-check"></i><b>6.7</b> Marginal effects</a><ul>
<li class="chapter" data-level="6.7.1" data-path="chapter-5.html"><a href="chapter-5.html#direct-marginal-effects"><i class="fa fa-check"></i><b>6.7.1</b> Direct marginal effects</a></li>
<li class="chapter" data-level="6.7.2" data-path="chapter-5.html"><a href="chapter-5.html#cross-marginal-effects"><i class="fa fa-check"></i><b>6.7.2</b> Cross-marginal effects</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="chapter-5.html"><a href="chapter-5.html#elasticity"><i class="fa fa-check"></i><b>6.8</b> Elasticity</a><ul>
<li class="chapter" data-level="6.8.1" data-path="chapter-5.html"><a href="chapter-5.html#direct-point-elasticity"><i class="fa fa-check"></i><b>6.8.1</b> Direct-point elasticity</a></li>
<li class="chapter" data-level="6.8.2" data-path="chapter-5.html"><a href="chapter-5.html#cross-point-elasticity"><i class="fa fa-check"></i><b>6.8.2</b> Cross-point elasticity</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="chapter-5.html"><a href="chapter-5.html#calculating-elasticities-based-on-an-mlogit-model"><i class="fa fa-check"></i><b>6.9</b> Calculating elasticities based on an <code>mlogit</code> model</a><ul>
<li class="chapter" data-level="6.9.1" data-path="chapter-5.html"><a href="chapter-5.html#computing-the-marginal-effects"><i class="fa fa-check"></i><b>6.9.1</b> Computing the marginal effects</a></li>
<li class="chapter" data-level="6.9.2" data-path="chapter-5.html"><a href="chapter-5.html#computing-the-elasticities"><i class="fa fa-check"></i><b>6.9.2</b> Computing the elasticities</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="chapter-5.html"><a href="chapter-5.html#a-note-about-attributes-in-dummy-format"><i class="fa fa-check"></i><b>6.10</b> A note about attributes in dummy format</a></li>
<li class="chapter" data-level="6.11" data-path="chapter-5.html"><a href="chapter-5.html#willingness-to-pay-and-discount-rate"><i class="fa fa-check"></i><b>6.11</b> Willingness to pay and discount rate</a></li>
<li class="chapter" data-level="6.12" data-path="chapter-5.html"><a href="chapter-5.html#simulating-market-changes"><i class="fa fa-check"></i><b>6.12</b> Simulating market changes</a><ul>
<li class="chapter" data-level="6.12.1" data-path="chapter-5.html"><a href="chapter-5.html#incentives"><i class="fa fa-check"></i><b>6.12.1</b> Incentives</a></li>
<li class="chapter" data-level="6.12.2" data-path="chapter-5.html"><a href="chapter-5.html#introduction-of-a-new-system"><i class="fa fa-check"></i><b>6.12.2</b> Introduction of a new system</a></li>
</ul></li>
<li class="chapter" data-level="6.13" data-path="chapter-5.html"><a href="chapter-5.html#exercise-4"><i class="fa fa-check"></i><b>6.13</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter-6.html"><a href="chapter-6.html"><i class="fa fa-check"></i><b>7</b> Non-Proportional Substitution Patterns I: Generalized Extreme Value Models</a><ul>
<li class="chapter" data-level="7.1" data-path="chapter-6.html"><a href="chapter-6.html#preliminaries-4"><i class="fa fa-check"></i><b>7.1</b> Preliminaries</a></li>
<li class="chapter" data-level="7.2" data-path="chapter-6.html"><a href="chapter-6.html#the-limits-of-perfection"><i class="fa fa-check"></i><b>7.2</b> The limits of perfection</a></li>
<li class="chapter" data-level="7.3" data-path="chapter-6.html"><a href="chapter-6.html#how-to-use-this-note-5"><i class="fa fa-check"></i><b>7.3</b> How to use this note</a></li>
<li class="chapter" data-level="7.4" data-path="chapter-6.html"><a href="chapter-6.html#learning-objectives-6"><i class="fa fa-check"></i><b>7.4</b> Learning objectives</a></li>
<li class="chapter" data-level="7.5" data-path="chapter-6.html"><a href="chapter-6.html#suggested-readings-5"><i class="fa fa-check"></i><b>7.5</b> Suggested readings</a></li>
<li class="chapter" data-level="7.6" data-path="chapter-6.html"><a href="chapter-6.html#generalized-extreme-value-models-a-recipe-for-deriving-discrete-choice-models"><i class="fa fa-check"></i><b>7.6</b> Generalized Extreme Value models: a recipe for deriving discrete choice models</a></li>
<li class="chapter" data-level="7.7" data-path="chapter-6.html"><a href="chapter-6.html#nested-logit-model"><i class="fa fa-check"></i><b>7.7</b> Nested Logit model</a></li>
<li class="chapter" data-level="7.8" data-path="chapter-6.html"><a href="chapter-6.html#properties-of-the-nested-logit-model"><i class="fa fa-check"></i><b>7.8</b> Properties of the nested logit model</a></li>
<li class="chapter" data-level="7.9" data-path="chapter-6.html"><a href="chapter-6.html#estimation-of-the-nested-logit-model"><i class="fa fa-check"></i><b>7.9</b> Estimation of the nested logit model</a></li>
<li class="chapter" data-level="7.10" data-path="chapter-6.html"><a href="chapter-6.html#substitution-patterns-with-the-nested-logit-model"><i class="fa fa-check"></i><b>7.10</b> Substitution patterns with the nested logit model</a></li>
<li class="chapter" data-level="7.11" data-path="chapter-6.html"><a href="chapter-6.html#elasticities-of-the-nested-logit-model"><i class="fa fa-check"></i><b>7.11</b> Elasticities of the nested logit model</a></li>
<li class="chapter" data-level="7.12" data-path="chapter-6.html"><a href="chapter-6.html#exercise-5"><i class="fa fa-check"></i><b>7.12</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter-7.html"><a href="chapter-7.html"><i class="fa fa-check"></i><b>8</b> Non-Proportional Substitution Patterns I: The Probit Model</a><ul>
<li class="chapter" data-level="8.1" data-path="chapter-7.html"><a href="chapter-7.html#preliminaries-5"><i class="fa fa-check"></i><b>8.1</b> Preliminaries</a></li>
<li class="chapter" data-level="8.2" data-path="chapter-7.html"><a href="chapter-7.html#more-flexible-substitution-patterns"><i class="fa fa-check"></i><b>8.2</b> More flexible substitution patterns</a></li>
<li class="chapter" data-level="8.3" data-path="chapter-7.html"><a href="chapter-7.html#how-to-use-this-note-6"><i class="fa fa-check"></i><b>8.3</b> How to use this note</a></li>
<li class="chapter" data-level="8.4" data-path="chapter-7.html"><a href="chapter-7.html#learning-objectives-7"><i class="fa fa-check"></i><b>8.4</b> Learning objectives</a></li>
<li class="chapter" data-level="8.5" data-path="chapter-7.html"><a href="chapter-7.html#suggested-readings-6"><i class="fa fa-check"></i><b>8.5</b> Suggested readings</a></li>
<li class="chapter" data-level="8.6" data-path="chapter-7.html"><a href="chapter-7.html#probit-model"><i class="fa fa-check"></i><b>8.6</b> Probit model</a></li>
<li class="chapter" data-level="8.7" data-path="chapter-7.html"><a href="chapter-7.html#exercise-6"><i class="fa fa-check"></i><b>8.7</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapter-8.html"><a href="chapter-8.html"><i class="fa fa-check"></i><b>9</b> Dealing with Heterogeneity I: The Mixed Logit Model</a><ul>
<li class="chapter" data-level="9.1" data-path="chapter-8.html"><a href="chapter-8.html#preliminaries-6"><i class="fa fa-check"></i><b>9.1</b> Preliminaries</a></li>
<li class="chapter" data-level="9.2" data-path="chapter-8.html"><a href="chapter-8.html#taste-variations-in-the-population"><i class="fa fa-check"></i><b>9.2</b> Taste variations in the population</a></li>
<li class="chapter" data-level="9.3" data-path="chapter-8.html"><a href="chapter-8.html#how-to-use-this-note-7"><i class="fa fa-check"></i><b>9.3</b> How to use this note</a></li>
<li class="chapter" data-level="9.4" data-path="chapter-8.html"><a href="chapter-8.html#learning-objectives-8"><i class="fa fa-check"></i><b>9.4</b> Learning objectives</a></li>
<li class="chapter" data-level="9.5" data-path="chapter-8.html"><a href="chapter-8.html#suggested-readings-7"><i class="fa fa-check"></i><b>9.5</b> Suggested readings</a></li>
<li class="chapter" data-level="9.6" data-path="chapter-8.html"><a href="chapter-8.html#mixed-logit"><i class="fa fa-check"></i><b>9.6</b> Mixed logit</a></li>
<li class="chapter" data-level="9.7" data-path="chapter-8.html"><a href="chapter-8.html#estimation-1"><i class="fa fa-check"></i><b>9.7</b> Estimation</a></li>
<li class="chapter" data-level="9.8" data-path="chapter-8.html"><a href="chapter-8.html#practical-example"><i class="fa fa-check"></i><b>9.8</b> Practical example</a></li>
<li class="chapter" data-level="9.9" data-path="chapter-8.html"><a href="chapter-8.html#behavioral-insights-from-the-mixed-logit-model"><i class="fa fa-check"></i><b>9.9</b> Behavioral insights from the mixed logit model</a><ul>
<li class="chapter" data-level="9.9.1" data-path="chapter-8.html"><a href="chapter-8.html#unconditional-distribution-of-a-random-parameter"><i class="fa fa-check"></i><b>9.9.1</b> Unconditional distribution of a random parameter</a></li>
<li class="chapter" data-level="9.9.2" data-path="chapter-8.html"><a href="chapter-8.html#conditional-distribution-of-the-random-coefficients"><i class="fa fa-check"></i><b>9.9.2</b> Conditional distribution of the random coefficients</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="chapter-8.html"><a href="chapter-8.html#using-covariates-to-capture-variations-in-taste"><i class="fa fa-check"></i><b>9.10</b> Using covariates to capture variations in taste</a></li>
<li class="chapter" data-level="9.11" data-path="chapter-8.html"><a href="chapter-8.html#revisiting-the-example"><i class="fa fa-check"></i><b>9.11</b> Revisiting the example</a></li>
<li class="chapter" data-level="9.12" data-path="chapter-8.html"><a href="chapter-8.html#full-covariance-matrix-for-random-components"><i class="fa fa-check"></i><b>9.12</b> Full covariance matrix for random components</a></li>
<li class="chapter" data-level="9.13" data-path="chapter-8.html"><a href="chapter-8.html#final-remarks"><i class="fa fa-check"></i><b>9.13</b> Final remarks</a></li>
<li class="chapter" data-level="9.14" data-path="chapter-8.html"><a href="chapter-8.html#exercise-7"><i class="fa fa-check"></i><b>9.14</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chapter-9.html"><a href="chapter-9.html"><i class="fa fa-check"></i><b>10</b> Dealing with Heterogeneity II: The Latent Class Logit Model</a><ul>
<li class="chapter" data-level="10.1" data-path="chapter-9.html"><a href="chapter-9.html#preliminaries-7"><i class="fa fa-check"></i><b>10.1</b> Preliminaries</a></li>
<li class="chapter" data-level="10.2" data-path="chapter-9.html"><a href="chapter-9.html#more-on-taste-variation"><i class="fa fa-check"></i><b>10.2</b> More on taste variation</a></li>
<li class="chapter" data-level="10.3" data-path="chapter-9.html"><a href="chapter-9.html#how-to-use-this-note-8"><i class="fa fa-check"></i><b>10.3</b> How to use this note</a></li>
<li class="chapter" data-level="10.4" data-path="chapter-9.html"><a href="chapter-9.html#learning-objectives-9"><i class="fa fa-check"></i><b>10.4</b> Learning objectives</a></li>
<li class="chapter" data-level="10.5" data-path="chapter-9.html"><a href="chapter-9.html#suggested-readings-8"><i class="fa fa-check"></i><b>10.5</b> Suggested readings</a></li>
<li class="chapter" data-level="10.6" data-path="chapter-9.html"><a href="chapter-9.html#latent-class-logit"><i class="fa fa-check"></i><b>10.6</b> Latent class logit</a></li>
<li class="chapter" data-level="10.7" data-path="chapter-9.html"><a href="chapter-9.html#estimation-2"><i class="fa fa-check"></i><b>10.7</b> Estimation</a></li>
<li class="chapter" data-level="10.8" data-path="chapter-9.html"><a href="chapter-9.html#properties-of-the-latent-class-logit-model"><i class="fa fa-check"></i><b>10.8</b> Properties of the latent class logit model</a></li>
<li class="chapter" data-level="10.9" data-path="chapter-9.html"><a href="chapter-9.html#empirical-example"><i class="fa fa-check"></i><b>10.9</b> Empirical example</a></li>
<li class="chapter" data-level="10.10" data-path="chapter-9.html"><a href="chapter-9.html#adding-individual-level-attributes"><i class="fa fa-check"></i><b>10.10</b> Adding individual-level attributes</a></li>
<li class="chapter" data-level="10.11" data-path="chapter-9.html"><a href="chapter-9.html#adding-variables-to-the-latent-class-selection-model"><i class="fa fa-check"></i><b>10.11</b> Adding variables to the latent class selection model</a></li>
<li class="chapter" data-level="10.12" data-path="chapter-9.html"><a href="chapter-9.html#exercise-8"><i class="fa fa-check"></i><b>10.12</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Discrete Choice Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter-4" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Practical specification and estimation</h1>
<blockquote>
<p>“In theory, there is no difference between theory and practice. But in practice, there is.”</p>
<p>— Benjamin Brewster</p>
</blockquote>
<blockquote>
<p>“An ounce of practice is generally worth more than a ton of theory.</p>
<p>— E.F. Schumacher</p>
</blockquote>
<div id="theory-and-practice" class="section level2">
<h2><span class="header-section-number">5.1</span> Theory and practice</h2>
<p>Chapters <a href="chapter-2.html#chapter-2">3</a> and <a href="chapter-3.html#chapter-3">4</a> presented a conceptual framework (a theory of behavior) and the necessary apparatus (based on probability theory) to implement the conceptual framework. This theoretical introduction was necessary to begin work from a solid foundation, and it provides an intuitive and elegant framework to study decision-making, and a powerful one too; Daniel McFadden was awarded the Sveriges Riksbank Prize in Economic Sciences (<a href="https://www.nobelprize.org/prizes/economic-sciences/2000/mcfadden/diploma/">Nobel Prize</a>) for his contributions to random utility modelling.</p>
<p>Although not described in detail in previous chapters, it is worthwhile to dwell for a moment on the history of the development of the logit model as a random utility model.</p>
<p>In his Nobel Lecture, <a href="https://en.wikipedia.org/wiki/Daniel_McFadden">McFadden</a> <span class="citation">(<a href="#ref-McFadden2001economic">2001</a>)</span> recounts the path that led to the development of random utility models for discrete choices. Like most important discoveries, it is a meandering path. It began early in the 20th century with a theory for economic behavior (i.e., utility) that considered heterogeneous preferences that in practice were difficult to verify empirically because of data limitations. Indeed, studies before the 1960s mostly considered aggregated demand with representative agents (i.e., archetypical consumers) to accommodate this limitation in data availability. It was only when individual-level data became more widely collected and within reach of researchers that it became possible to pay attention to the behavior of individual agents.</p>
<p>While economists were busy with models of aggregated demand, research in psychometrics and mathematical psychology by <a href="https://en.wikipedia.org/wiki/Louis_Leon_Thurstone">L.L Thurstone</a> and <a href="https://en.wikipedia.org/wiki/R._Duncan_Luce">R.D. Luce</a> was busy providing the technical basis for modelling what Thurstone termed <em>Comparative Judgement</em> (in the sense of making a decision or forming an opinion). In particular, Luce introduced the axiom of Independence of Irrelevant Alternatives (discussed in Chapter <a href="chapter-3.html#chapter-3">4</a>). According to McFadden (2001, p. 353), this axiom “simplified experimental collection of choice data by allowing multinomial choice probabilities to be inferred from binomial choice experiments.” <a href="https://en.wikipedia.org/wiki/Jacob_Marschak">J. Marschak</a> was the first to introduce the work of Thurstone to econometrics in 1960, and also the author of the term <em>Random Utility Maximizing</em> (RUM) that eventually prevailed over the comparative judgement terminology of Thurstone. McFadden’s early contributions to this body of research was developing an econometric version of Luce’s model, with strict (i.e., systematic) utilities specified as functions of the attributes of the alternatives and linking unobserved preference heterogeneity to a fully consistent description of the distribution of demands. Since the 1970s, discrete choice analysis has been a burgeoning area of research with a plethora of applications in economics, marketing, and travel behavior, among many others.</p>
<p>This brief story neatly illustrates the complex interplay between theory and practice.</p>
<p>Early attempts to study demand were limited due to practical considerations (i.e., the absence of data at the individual level). Once appropriate data became available, new studies continued to push the theoretical envelope. Indeed, theoretical questions have continued to inspire newer way to collect data and novel methods, and these in turn have helped us to refine our understanding of behavior. See as an example the work on decision-making in social situations <span class="citation">(Akerlof <a href="#ref-Akerlof1997social">1997</a>; K. Axhausen <a href="#ref-Axhausen2005social">2005</a>; A. Páez and Scott <a href="#ref-Paez2007social">2007</a>)</span> which inspired the use of new data sources <span class="citation">(e.g., J. A. Carrasco et al. <a href="#ref-Carrasco2007social">2008</a> <span class="citation">K. W. Axhausen (<a href="#ref-Axhausen2008social">2008</a>)</span>; Scott et al. <a href="#ref-Scott2012social">2012</a>; Chen and Mahmassani <a href="#ref-Chen2016social">2016</a>)</span> as well as novel modelling approaches <span class="citation">(e.g., Dugundji and Walker <a href="#ref-Dugundji2005discrete">2005</a>; Dugundji and Gulyas <a href="#ref-Dugundji2013social">2013</a>; Kamargianni, Ben-Akiva, and Polydoropoulou <a href="#ref-Kamargianni2014social">2014</a>)</span> and empirical work <span class="citation">(e.g., Berg, Arentze, and Timmermans <a href="#ref-vandenBerg2009social">2009</a>; Goetzke and Rave <a href="#ref-Goetzke2011bicycle">2011</a>; Matous <a href="#ref-Matous2017social">2017</a>)</span>.</p>
<p>Now that the preceding chapters have armed us with the theory and basic concepts to implement random utility modelling, it is proper that we turn our attention to the practical aspects of modelling. The best way to ensure that the concepts take hold, in my view, is to get your hands on a dataset and struggle with the practicalities of cleaning and organizing data, specifying the utility functions (a task that is more art than science), and estimating models. These skills are mostly transferable to other modelling techniques, so we will begin by applying them to the most fundamental discrete choice model, the multinomial logit.</p>
</div>
<div id="how-to-use-this-note-3" class="section level2">
<h2><span class="header-section-number">5.2</span> How to use this note</h2>
<p>Remember that the source for the document you are reading is an R Notebook. Throughout the notes, you will find examples of code in segments of text called <em>chunks</em>. This is an example of a chunk:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="st">&quot;Hats off to you, Prof. McFadden&quot;</span>)</code></pre></div>
<pre><code>## [1] &quot;Hats off to you, Prof. McFadden&quot;</code></pre>
<p>If you are working with the Notebook version of the document, you can run the code by clicking the ‘play’ icon on the top right corner of the chunk. If you are reading the web-book version of the document, you will often see that the code has already been executed. You can still try it by copying and pasting into your R or RStudio console.</p>
</div>
<div id="learning-objectives-4" class="section level2">
<h2><span class="header-section-number">5.3</span> Learning objectives</h2>
<p>In this practice, you will learn about:</p>
<ol style="list-style-type: decimal">
<li>Specification of utility functions.</li>
<li>Maximum likelihood estimation.</li>
<li>Estimation of multinomial logit models.</li>
<li>McFadden’s <span class="math inline">\(\rho^2\)</span></li>
<li>The likelihood ratio test.</li>
</ol>
</div>
<div id="suggested-readings-3" class="section level2">
<h2><span class="header-section-number">5.4</span> Suggested readings</h2>
<ul>
<li>Ben-Akiva, M. Lerman, <span class="citation">(<a href="#ref-Benakiva1985discrete">1985</a>)</span> Discrete Choice Analysis: Theory and Applications to Travel Demand, <strong>Chapters 4 and 5</strong>, MIT Press.</li>
<li>Hensher, D.A., Rose, J.M., Greene, W.H <span class="citation">(<a href="#ref-hensher2005applied">2005</a>)</span> Applied Choice Analysis: A Primer, <strong>Chapter 10</strong>, Cambridge University Press.</li>
<li>Ortuzar JD, Willumsen LG <span class="citation">(<a href="#ref-Ortuzar2011modelling">2011</a>)</span> Modelling Transport, Fourth Edition, <strong>Chapter 8</strong>, John Wiley and Sons.</li>
<li>Train <span class="citation">(<a href="#ref-Train2009discrete">2009</a>)</span> Discrete Choice Methods with Simulation, Second Edition, <strong>Chapter 3</strong>, Cambridge University Press.</li>
</ul>
</div>
<div id="preliminaries-2" class="section level2">
<h2><span class="header-section-number">5.5</span> Preliminaries</h2>
<p>Load the packages used in this section:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(evd)
<span class="kw">library</span>(mlogit)
<span class="kw">library</span>(kableExtra)
<span class="kw">library</span>(plotly)</code></pre></div>
<pre><code>## 
## Attaching package: &#39;plotly&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     last_plot</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     filter</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     layout</code></pre>
<p>Load the dataset used in this section:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="st">&quot;Commute Mac.RData&quot;</span>)</code></pre></div>
</div>
<div id="the-anatomy-of-utility-functions" class="section level2">
<h2><span class="header-section-number">5.6</span> The anatomy of utility functions</h2>
<p>At the end Chapter <a href="chapter-3.html#chapter-3">4</a> we took, for the first time, a closer look at the systematic utilities of discrete choice models. It is useful to think about the anatomy of a typical systematic utility function. Previously, we said that some variables vary across utility functions; these are typically the attributes that describe the various alternatives (e.g., level of service and cost). The variables that describe the decision-maker do <em>not</em> vary by alternative. This has implications, as seen before, for how the variables are entered into the functions. Since the model works on the basis of <em>differences</em> between utilities, the attributes must actually measure different levels of something or vanish.</p>
<p>We will describe the utilities in terms of the way different variables are introduced in the utility functions. As before, we will assume that the location parameters of the distribution are absorbed by <span class="math inline">\(J-1\)</span> utility functions (where <span class="math inline">\(J\)</span> is the number of alternatives).</p>
<p>Consider first variables that vary across alternatives. These variables can have a generic coefficient or they can have alternative-specific coefficients, as seen here:</p>
<p>$$</p>
<span class="math display">\[\begin{array}{l}
                V_{i1} =\\
                V_{i2} =\\
                V_{i3} =\\
              \end{array}\]</span>
<p>^ _{} ^{} $$</p>
<p>In many cases it sensible to have generic coefficients. For instance, if the variable is cost, we might assume that one dollar is valued equally irrespective of the it is spent on alternative. In other cases, alternative-specific coefficients might be informative. For instance, a consistent finding is that time spent traveling by public transportation is perceived as being more expensive than time traveling by car. Occasionally, as well, an attribute might be specific to an alternative: for instance, waiting time is often implicitly zero for travel by car and active modes of transportation (i.e., walking and cycling).</p>
<p>The differences of the utilities are as follows:</p>
<p><span class="math display">\[
\begin{array}{lll}
    V_{i2}-V_{i1}=&amp;(\mu_2 - 0) &amp; + &amp;\beta_1(x_{i2} - x_{i1}) &amp; + &amp;(\delta_2w_{i2} - \delta_1w_{i1})\\
    V_{i3}-V_{i1}=&amp;(\mu_3 - 0) &amp; + &amp;\beta_1(x_{i2} - x_{i1}) &amp; + &amp;(\delta_3w_{i3} -  \delta_1w_{i1})\\
    V_{i3}-V_{i2}=&amp;(\mu_3- \mu_2) &amp; + &amp;\beta_1(x_{i2} - x_{i1}) &amp; + &amp;(\delta_3w_{i3} - \delta_2w_{i2})\\
\end{array}
\]</span></p>
<p>Variables that vary across individuals but not by alternative can be introduced with alternative-specific coefficients: $$</p>
<span class="math display">\[\begin{array}{l}
                V_{i1} =\\
                V_{i2} =\\
                V_{i3} =\\
              \end{array}\]</span>
<p>^ _{}</p>
<p>^{} _ $$</p>
<p>Following the example above, the differences of utilities are: <span class="math display">\[
\begin{array}{lll}
    V_{i2}-V_{i1}=&amp;(\mu_2 - 0) &amp; + &amp;\beta_1(x_{i2} - x_{i1}) &amp; + &amp;(\delta_2w_{i2} - \delta_1w_{i1}) &amp; + &amp;(\gamma_2 - 0)z_i\\
    V_{i3}-V_{i1}=&amp;(\mu_3 - 0) &amp; + &amp;\beta_1(x_{i2} - x_{i1}) &amp; + &amp;(\delta_3w_{i3} -  \delta_1w_{i1}) &amp; + &amp;(\gamma_3 - 0)z_i\\
    V_{i3}-V_{i2}=&amp;(\mu_3- \mu_2) &amp; + &amp;\beta_1(x_{i2} - x_{i1}) &amp; + &amp;(\delta_3w_{i3} - \delta_2w_{i2}) &amp; + &amp;(\gamma_3 - \gamma_2)z_i\\
\end{array}
\]</span></p>
<p>As an alternative, individual-level variables can be introduced as part of an expansion of some coefficients, for example: $$</p>
<span class="math display">\[\begin{array}{l}
                V_{i1} =\\
                V_{i2} =\\
                V_{i3} =\\
              \end{array}\]</span>
<p>^ _{} ^{} $$</p>
<p>The above expands to: $$</p>
<span class="math display">\[\begin{array}{l}
                V_{i1} =\\
                V_{i2} =\\
                V_{i3} =\\
              \end{array}\]</span>
<p>^ _{} ^{} $$</p>
<p>And so the differences in utilities are: <span class="math display">\[
\begin{array}{lll}
    V_{i2}-V_{i1}=&amp;(\mu_2 - 0) &amp; + &amp;\beta_{11}(x_{i2} - x_{i1}) &amp; + &amp;\beta_{11}(z_ix_{i2} - z_ix_{i1}) &amp; + &amp;(\delta_2w_{i2} - \delta_1w_{i1})\\
    V_{i3}-V_{i1}=&amp;(\mu_3 - 0) &amp; + &amp;\beta_{11}(x_{i2} - x_{i1}) &amp; + &amp;\beta_{11}(z_ix_{i3} - z_ix_{i1}) &amp; + &amp;(\delta_3w_{i3} -  \delta_1w_{i1})\\
    V_{i3}-V_{i2}=&amp;(\mu_3- \mu_2) &amp; + &amp;\beta_{11}(x_{i2} - x_{i1}) &amp; + &amp;\beta_{11}(z_ix_{i3} - z_ix_{i2}) &amp; + &amp;(\delta_3w_{i3} - \delta_2w_{i2})\\
\end{array}
\]</span></p>
<p>Understanding the anatomy of utility functions is essential to properly specify and estimate models.</p>
</div>
<div id="example-specifying-the-utility-functions" class="section level2">
<h2><span class="header-section-number">5.7</span> Example: Specifying the utility functions</h2>
<p>We will now proceed to work with a practical example, using the dataset that you encountered before in Chapter <a href="chapter-1.html#chapter-1">2</a>. This dataset contains information on various modes of transportation used by people commuting to McMaster University in Canada <span class="citation">(Whalen, Páez, and Carrasco <a href="#ref-Whalen2013">2013</a>)</span>. The dataset was loaded above as part of the preliminaries of this chapter. We can begin by exploring the data. First, we notice that this is a dataframe that has been prepared for use with the <code>mlogit</code> package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(mc_commute)</code></pre></div>
<pre><code>## [1] &quot;mlogit.data&quot; &quot;data.frame&quot;</code></pre>
<p>Please note that this is the same dataset that you used in Chapter <a href="chapter-1.html#chapter-1">2</a>, but not the same file. For convenience, the dataset was pre-organized for use with <code>mlogit</code>. The contents of the dataframe can be quickly seen by means of the function <code>head()</code>. This function will display the first few top rows of the dataframe:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(mc_commute, <span class="dv">8</span>)</code></pre></div>
<pre><code>##                id choice HSR.access HSR.wait HSR.transfer parking vehind
## 1.Cycle 566872636  FALSE          3       15            0      No     No
## 1.Walk  566872636  FALSE          3       15            0      No     No
## 1.HSR   566872636   TRUE          3       15            0      No     No
## 1.Car   566872636  FALSE          3       15            0      No     No
## 2.Cycle 566873140  FALSE          4       15            0      No    Yes
## 2.Walk  566873140  FALSE          4       15            0      No    Yes
## 2.HSR   566873140   TRUE          4       15            0      No    Yes
## 2.Car   566873140  FALSE          4       15            0      No    Yes
##         gender age                          shared family child
## 1.Cycle   Male  21 Living in Shared Accommodations     No    No
## 1.Walk    Male  21 Living in Shared Accommodations     No    No
## 1.HSR     Male  21 Living in Shared Accommodations     No    No
## 1.Car     Male  21 Living in Shared Accommodations     No    No
## 2.Cycle   Male  23                              No     No    No
## 2.Walk    Male  23                              No     No    No
## 2.HSR     Male  23                              No     No    No
## 2.Car     Male  23                              No     No    No
##         street_density sidewalk_density      LAT      LONG   alt available
## 1.Cycle       14.37621         22.63322 43.26302 -79.90074   Car        No
## 1.Walk        14.37621         22.63322 43.26302 -79.90074 Cycle        No
## 1.HSR         14.37621         22.63322 43.26302 -79.90074   HSR       Yes
## 1.Car         14.37621         22.63322 43.26302 -79.90074  Walk       Yes
## 2.Cycle       19.49754         39.64003 43.25885 -79.90476   Car       Yes
## 2.Walk        19.49754         39.64003 43.25885 -79.90476 Cycle        No
## 2.HSR         19.49754         39.64003 43.25885 -79.90476   HSR       Yes
## 2.Car         19.49754         39.64003 43.25885 -79.90476  Walk       Yes
##                 time chid
## 1.Cycle 1.000000e+05    1
## 1.Walk  6.211180e+00    1
## 1.HSR   5.000000e+00    1
## 1.Car   2.131439e+01    1
## 2.Cycle 2.000000e+00    2
## 2.Walk  3.726708e+00    2
## 2.HSR   1.000000e+01    2
## 2.Car   1.278863e+01    2</code></pre>
<p>As you can see, the dataframe has been organized in a particular way. Now, instead of each row being an individual, each row is a choice situation. Since there are four alternatives in this case, each row corresponds to the choice situation for an alternative for an individual. We notice that the row names now have the format <code>#.Alt</code>, where <code>#</code> is the number of the decision maker and <code>Alt</code> is the name of the alternative. In this way the first four rows of the table correspond to the first decision-maker who, faced with four alternatives, chose HSR (public transportation) - as recorded in the column <code>choice</code>. The next four rows correspond to the second decision-maker in the sample (who also chose HSR), and so on, four rows per decision-maker. More generally, there will be <span class="math inline">\(J\)</span> ro. And so on.</p>
<p>The first step is to specify the utility functions for the desired model. The package <code>mlogit</code> uses for formuals <code>mFormula</code> objects that build upon the <a href="https://CRAN.R-project.org/package=Formula"><code>Formula</code> package</a> for multi-component formulas. As seen above, utility functions can potentially have multiple components, so the utilities to build formulas are quite useful.</p>
<p>Formulas for the <code>mlogit</code> package are defined using three parts: <span class="math display">\[
\text{choice} \sim \text{alternative specific vars with generic coefficients }|\text{ individual specific vars }|\text{ alternative specific vars with specific coefficients}  
\]</span></p>
<p>If we list all columns in the dataframe, we can see what variables are available for this analysis:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">colnames</span>(mc_commute)</code></pre></div>
<pre><code>##  [1] &quot;id&quot;               &quot;choice&quot;           &quot;HSR.access&quot;      
##  [4] &quot;HSR.wait&quot;         &quot;HSR.transfer&quot;     &quot;parking&quot;         
##  [7] &quot;vehind&quot;           &quot;gender&quot;           &quot;age&quot;             
## [10] &quot;shared&quot;           &quot;family&quot;           &quot;child&quot;           
## [13] &quot;street_density&quot;   &quot;sidewalk_density&quot; &quot;LAT&quot;             
## [16] &quot;LONG&quot;             &quot;alt&quot;              &quot;available&quot;       
## [19] &quot;time&quot;             &quot;chid&quot;</code></pre>
<p>Besides identifier variable <code>id</code> and <code>chid</code>, and the variable for <code>choice</code>, we see that several variables are specific to the individual decision-makers. These are <code>parking</code> (availability of a parking pass), <code>vehind</code> (whether the decision-maker has individual access to a private vehicle), <code>gender</code>, <code>age</code>, <code>shared</code> (living in shared accommodations away from the family home), <code>family</code> (living at the family home), and <code>child</code> (minors are present in the household). Furthermore, some variables relate to the physical environment of the place of residence (<code>street_density</code> and <code>sidewalk_density</code>), in addition to the coordinates of the place of residence (geocoded to the nearest major intersection or postal code centroid). One variable is alternative specific, namely <code>time</code> (travel time in minutes). And three variables are specific to public transportation, namely <code>HSR.access</code> (access time to public transportation in minutes), <code>HSR.wait</code> (waiting time in minutes), and <code>HSR.transfer</code> (number of transfers when traveling by public transportation).</p>
<p>We can begin by defining a very simple formula that considers only travel time. We will call this <code>f1</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f1 &lt;-<span class="st"> </span><span class="kw">mFormula</span>(choice <span class="op">~</span><span class="st"> </span>time)</code></pre></div>
<p>The function <code>model.matrix</code> allows us to see how the formula is applied to the data (we use <code>head()</code> to display only the top rows of the model matrix):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">model.matrix</span>(f1, mc_commute), <span class="dv">8</span>)</code></pre></div>
<pre><code>##         Walk:(intercept) HSR:(intercept) Car:(intercept)         time
## 1.Cycle                0               0               0 1.000000e+05
## 1.Walk                 1               0               0 6.211180e+00
## 1.HSR                  0               1               0 5.000000e+00
## 1.Car                  0               0               1 2.131439e+01
## 2.Cycle                0               0               0 2.000000e+00
## 2.Walk                 1               0               0 3.726708e+00
## 2.HSR                  0               1               0 1.000000e+01
## 2.Car                  0               0               1 1.278863e+01</code></pre>
<p>We can see that the formula includes by default the alternative specific coefficients, in this case using as a reference cycling. The corresponding utility functions are as follows:</p>
<p><span class="math display">\[
\begin{array}{l}
                V_{i\text{Cycle}} =\\
                V_{i\text{Walk}} =\\
                V_{i\text{HSR}} =\\
                V_{i\text{HSR}} =\\
              \end{array}  
  \overbrace{ \begin{array}{lll}
                0 &amp; +0 &amp; +0\\
                \mu_{\text{Walk}} &amp; +0 &amp; +0\\
                0 &amp; +\mu_{\text{HSR}} &amp; +0 \\
                0 &amp; +0 &amp; +\mu_{\text{Car}}\\
              \end{array}
              }^\text{alternative specific constants} 
  \underbrace{\begin{array}{lll}
                +\beta_1\text{time}_{i\text{Cycle}}\\
                +\beta_1\text{time}_{i\text{Walk}}\\
                +\beta_1\text{time}_{i\text{HSR}}\\
                +\beta_1\text{time}_{i\text{Car}}\\
              \end{array}
              }_{\text{alternative vars. with generic coefficients}}
\]</span></p>
<p>Define now a formula with an individual-specific variable, say age, and call it <code>f2</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f2 &lt;-<span class="st"> </span><span class="kw">mFormula</span>(choice <span class="op">~</span><span class="st"> </span>time <span class="op">|</span><span class="st"> </span>age)</code></pre></div>
<p>The model matrix is now:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">model.matrix</span>(f2, mc_commute), <span class="dv">8</span>)</code></pre></div>
<pre><code>##         Walk:(intercept) HSR:(intercept) Car:(intercept)         time
## 1.Cycle                0               0               0 1.000000e+05
## 1.Walk                 1               0               0 6.211180e+00
## 1.HSR                  0               1               0 5.000000e+00
## 1.Car                  0               0               1 2.131439e+01
## 2.Cycle                0               0               0 2.000000e+00
## 2.Walk                 1               0               0 3.726708e+00
## 2.HSR                  0               1               0 1.000000e+01
## 2.Car                  0               0               1 1.278863e+01
##         Walk:age HSR:age Car:age
## 1.Cycle        0       0       0
## 1.Walk        21       0       0
## 1.HSR          0      21       0
## 1.Car          0       0      21
## 2.Cycle        0       0       0
## 2.Walk        23       0       0
## 2.HSR          0      23       0
## 2.Car          0       0      23</code></pre>
<p>And the utility functions are therefore:</p>
<p><span class="math display">\[
\begin{array}{l}
                V_{i\text{Cycle}} =\\
                V_{i\text{Walk}} =\\
                V_{i\text{HSR}} =\\
                V_{i\text{HSR}} =\\
              \end{array}  
  \overbrace{ \begin{array}{lll}
                0 &amp; +0 &amp; +0\\
                \mu_{\text{Walk}} &amp; +0 &amp; +0\\
                0 &amp; +\mu_{\text{HSR}} &amp; +0 \\
                0 &amp; +0 &amp; +\mu_{\text{Car}}\\
              \end{array}
              }^\text{alternative specific constants} 
  \underbrace{\begin{array}{lll}
                +\beta_1\text{time}_{i\text{Cycle}}\\
                +\beta_1\text{time}_{i\text{Walk}}\\
                +\beta_1\text{time}_{i\text{HSR}}\\
                +\beta_1\text{time}_{i\text{Car}}\\
              \end{array}
              }_{\text{alternative vars. with generic coefficients}}
  \overbrace{ \begin{array}{lll}
                0 &amp; +0 &amp; +0\\
                \gamma_{1}\text{age}_{i} &amp; +0 &amp; +0\\
                0 &amp; + \gamma_{2}\text{age}_{i} &amp; +0 \\
                0 &amp; +0 &amp; +\gamma_{3}\text{age}_{i}\\
              \end{array}
              }^\text{individual vars with specific coefficients} 
\]</span></p>
<p>Lets try a different formula, where time has alternative-specific instead of generic coefficients, and call it <code>f3</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f3 &lt;-<span class="st"> </span><span class="kw">mFormula</span>(choice <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">|</span><span class="st"> </span>age <span class="op">|</span><span class="st"> </span>time)</code></pre></div>
<p>Note that, since we do not define other alternative-specific variables with generic coefficients, we have to explicitly state that there are <code>0</code> such variables!</p>
<p>This formula leads to the following model matrix:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">model.matrix</span>(f3, mc_commute), <span class="dv">8</span>)</code></pre></div>
<pre><code>##         Walk:(intercept) HSR:(intercept) Car:(intercept) Walk:age HSR:age
## 1.Cycle                0               0               0        0       0
## 1.Walk                 1               0               0       21       0
## 1.HSR                  0               1               0        0      21
## 1.Car                  0               0               1        0       0
## 2.Cycle                0               0               0        0       0
## 2.Walk                 1               0               0       23       0
## 2.HSR                  0               1               0        0      23
## 2.Car                  0               0               1        0       0
##         Car:age Cycle:time Walk:time HSR:time Car:time
## 1.Cycle       0      1e+05  0.000000        0  0.00000
## 1.Walk        0      0e+00  6.211180        0  0.00000
## 1.HSR         0      0e+00  0.000000        5  0.00000
## 1.Car        21      0e+00  0.000000        0 21.31439
## 2.Cycle       0      2e+00  0.000000        0  0.00000
## 2.Walk        0      0e+00  3.726708        0  0.00000
## 2.HSR         0      0e+00  0.000000       10  0.00000
## 2.Car        23      0e+00  0.000000        0 12.78863</code></pre>
<p>The utility functions for this are:</p>
$$
<span class="math display">\[\begin{array}{l}
                V_{i\text{Cycle}} =\\
                V_{i\text{Walk}} =\\
                V_{i\text{HSR}} =\\
                V_{i\text{HSR}} =\\
              \end{array}\]</span>
<p>^ _ ^{}</p>
<p>$$</p>
<p>Given the utility functions, the logit probabilities for each alternative are:</p>
<p><span class="math display">\[
\begin{array}{l}
    P(\text{Cycle}) = \frac{e^{V_{\text{Cycle}}}}{e^{V_{\text{Cycle}}}+e^{V_{\text{Walk}}}+e^{V_{\text{HSR}}}+e^{V_{\text{Car}}}}\\
    P(\text{Walk}) = \frac{e^{V_{\text{Walk}}}}{e^{V_{\text{Cycle}}}+e^{V_{\text{Walk}}}+e^{V_{\text{HSR}}}+e^{V_{\text{Car}}}}\\
    P(\text{HSR}) = \frac{e^{V_{\text{Cycle}}}}{e^{V_{\text{Cycle}}}+e^{V_{\text{Walk}}}+e^{V_{\text{HSR}}}+e^{V_{\text{Car}}}}\\
    P(\text{Car}) =1 - P(\text{Cycle}) - P(\text{Walk}) - P(\text{HSR})\\
\end{array}
\]</span></p>
<p>The utility functions depend on the data but also on the coefficients, which we do not know <em>a priori</em>. Rather, these must be retrieved from the sample, as discussed next.</p>
</div>
<div id="estimation" class="section level2">
<h2><span class="header-section-number">5.8</span> Estimation</h2>
<p>Before we can calculate the choice probabilities, we need to somehow obtain coefficients for the utility functions. The process to do so is called <em>estimation</em>, and it involves the use of a statistical sample.</p>
<p>To estimate the coefficients of a model we need to define a criterion. Estimates can take an infinite number of values, after all, so our criterion must be optimal in some sense - in this way, once that we estimate the coefficients we can be satisfied that the coefficients are the best that we can obtain given then inputs.</p>
<p>A common criterion used to estimate discrete choice models is the <em>likelihood</em>. So what is this likelihood? Previously we encountered probability distribution functions. These functions were defined by parameters (such as the location parameter and the dispersion parameter). Given the parameters, it is possible to calculate the probability of values for a variable <span class="math inline">\(x\)</span>. A likelihood function is a similar concept, except that whereas in the probability functions the parameters were given, in a likelihood function the data are given and the parameters need to be obtained from the function.</p>
<p>The relevant likelihood function for the multinomial logit model is as follows: <span class="math display">\[
L = \prod_{i=n}^N\prod_{j=1}^J P_{ij}^{y_{ij}}
\]</span> where <span class="math inline">\(P_{ij}\)</span> is the probability of decision-maker <span class="math inline">\(i\)</span> selecting alternative <span class="math inline">\(j\)</span> and <span class="math inline">\(y_{ij}\)</span> is an indicator variable that takes the value of <span class="math inline">\(1\)</span> if individual <span class="math inline">\(i\)</span> chose alternative <span class="math inline">\(j\)</span> and <span class="math inline">\(0\)</span> otherwise. The effect of the indicator variable is to turn the probabilities on and off, since <span class="math inline">\(P^0 = 1\)</span> and <span class="math inline">\(P^1 = P\)</span>. Notice that the likelihood function is bounded between 0 and 1, but in the case of the logit model is never exactly zero nor one, since the logit probabilities never thake those values.</p>
<p>Lets explore the behavior of this function by means of a simple example, with the binomial logit (i.e., only two alternative in the choice set), in which case the likelihood function becomes:</p>
<p><span class="math display">\[
L = \prod_{i=n}^N P_{iA}^{y_{iA}}P_{iB}^{y_{iB}} = 
    \Bigg(\frac{e^{V_{iA}}}{e^{V_{iA}} + e^{V_{iB}}}\Bigg)^{y_{iA}}
    \Bigg(\frac{e^{V_{iB}}}{e^{V_{iA}} + e^{V_{iB}}}\Bigg)^{y_{iB}}
\]</span></p>
<p>The utility functions <span class="math inline">\(V_{iA}\)</span> and <span class="math inline">\(V_{iB}\)</span> depend on the data, which we know (since we have a statistical sample), and the coefficients, which we do not know.</p>
For the example, we have the following toy sample with six individuals:
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
Individual
</th>
<th style="text-align:left;">
Choice
</th>
<th style="text-align:right;">
yiA
</th>
<th style="text-align:right;">
yiB
</th>
<th style="text-align:right;">
xiA
</th>
<th style="text-align:right;">
xiB
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
4
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
5
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
B
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
6
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
B
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:left;">
B
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
4
</td>
</tr>
</tbody>
</table>
<p>Based on this sample, we can specify the utility functions in this fashion:</p>
<p><span class="math display">\[
\begin{array}{l}
                V_{iA} = 0 &amp;+&amp; \beta x_{iA}\\
                V_{iB} = \mu &amp;+&amp; \beta x_{iB}\\
              \end{array}  
\]</span></p>
<p>These utility functions are very similar to the first set of utility function we defined in the preceding section for the case of mode choice.</p>
<p>Next, lets write the likelihood function for this toy sample, as a function of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\beta\)</span> and calculate the likelihood initially setting <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\beta\)</span> to zero. We will call this “Experiment 1”:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span><span class="dv">0</span>
beta &lt;-<span class="st"> </span><span class="dv">0</span>

P1A_<span class="dv">1</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">1</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">1</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">1</span>])))
P1B_<span class="dv">1</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">1</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">1</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">1</span>])))
P2A_<span class="dv">1</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">2</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">2</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">2</span>])))
P2B_<span class="dv">1</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">2</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">2</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">2</span>])))
P3A_<span class="dv">1</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">3</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">3</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">3</span>])))
P3B_<span class="dv">1</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">3</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">3</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">3</span>])))
P4A_<span class="dv">1</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">4</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">4</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">4</span>])))
P4B_<span class="dv">1</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">4</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">4</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">4</span>])))
P5A_<span class="dv">1</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">5</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">5</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">5</span>])))
P5B_<span class="dv">1</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">5</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">5</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">5</span>])))
P6A_<span class="dv">1</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">6</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">6</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">6</span>])))
P6B_<span class="dv">1</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">6</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">6</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">6</span>])))
  
L &lt;-<span class="st">  </span>P1A_<span class="dv">1</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>P1B_<span class="dv">1</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P2A_<span class="dv">1</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>P2B_<span class="dv">1</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P3A_<span class="dv">1</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>P3B_<span class="dv">1</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P4A_<span class="dv">1</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">4</span>] <span class="op">*</span><span class="st"> </span>P4B_<span class="dv">1</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">4</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P5A_<span class="dv">1</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">5</span>] <span class="op">*</span><span class="st"> </span>P5B_<span class="dv">1</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">5</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P6A_<span class="dv">1</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">6</span>] <span class="op">*</span><span class="st"> </span>P6B_<span class="dv">1</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">6</span>] 

<span class="co"># Create data frame to tabulate results:</span>
df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Individual =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>),
                 <span class="dt">Choice =</span> <span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;B&quot;</span>),
                 <span class="dt">PA =</span> <span class="kw">c</span>(P1A_<span class="dv">1</span>, P2A_<span class="dv">1</span>, P3A_<span class="dv">1</span>, P4A_<span class="dv">1</span>, P5A_<span class="dv">1</span>, P6A_<span class="dv">1</span>),
                 <span class="dt">PB =</span> <span class="kw">c</span>(P1B_<span class="dv">1</span>, P2B_<span class="dv">1</span>, P3B_<span class="dv">1</span>, P4B_<span class="dv">1</span>, P5B_<span class="dv">1</span>, P6B_<span class="dv">1</span>))

<span class="kw">kable</span>(df, <span class="st">&quot;html&quot;</span>, <span class="dt">digits =</span> <span class="dv">4</span>, <span class="dt">align =</span> <span class="st">&quot;c&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">bootstrap_options =</span> <span class="kw">c</span>(<span class="st">&quot;striped&quot;</span>, <span class="st">&quot;hover&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">footnote</span>(<span class="dt">general =</span> <span class="kw">paste</span>(<span class="st">&quot;The value of the likelihood function is &quot;</span>, <span class="kw">round</span>(L, <span class="dt">digits =</span> <span class="dv">4</span>)))</code></pre></div>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
Individual
</th>
<th style="text-align:center;">
Choice
</th>
<th style="text-align:center;">
PA
</th>
<th style="text-align:center;">
PB
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.5
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.5
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
B
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.5
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.5
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
B
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.5
</td>
</tr>
<tr>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
B
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.5
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<span style="font-style: italic;">Note: </span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> The value of the likelihood function is 0.0156
</td>
</tr>
</tfoot>
</table>
<p>As you can see, that the logit probabilities when all coefficients are zero is <span class="math inline">\(0.5\)</span>. By setting the coefficients to zero we have defined what is called a null model. Since the variables are set to zero, this model has no useful information to estimate the probability, and therefore it assigns equal probabilities to all alternative. The likelihood is a relatively small value.</p>
<p>Now lets change the coefficients (call this “Experiment 2”):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span><span class="fl">0.5</span> <span class="co"># -0.5</span>
beta &lt;-<span class="st"> </span><span class="op">-</span><span class="fl">1.5</span> <span class="co"># -0.5</span>

P1A_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">1</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">1</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">1</span>])))
P1B_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">1</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">1</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">1</span>])))
P2A_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">2</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">2</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">2</span>])))
P2B_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">2</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">2</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">2</span>])))
P3A_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">3</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">3</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">3</span>])))
P3B_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">3</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">3</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">3</span>])))
P4A_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">4</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">4</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">4</span>])))
P4B_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">4</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">4</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">4</span>])))
P5A_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">5</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">5</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">5</span>])))
P5B_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">5</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">5</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">5</span>])))
P6A_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">6</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">6</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">6</span>])))
P6B_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">6</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">6</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">6</span>])))
  
L &lt;-<span class="st">  </span>P1A_<span class="dv">2</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>P1B_<span class="dv">2</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P2A_<span class="dv">2</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>P2B_<span class="dv">2</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P3A_<span class="dv">2</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>P3B_<span class="dv">2</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P4A_<span class="dv">2</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">4</span>] <span class="op">*</span><span class="st"> </span>P4B_<span class="dv">2</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">4</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P5A_<span class="dv">2</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">5</span>] <span class="op">*</span><span class="st"> </span>P5B_<span class="dv">2</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">5</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P6A_<span class="dv">2</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">6</span>] <span class="op">*</span><span class="st"> </span>P6B_<span class="dv">2</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">6</span>] 

<span class="co"># Create data frame to tabulate results:</span>
df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Individual =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>),
                 <span class="dt">Choice =</span> <span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;B&quot;</span>),
                 <span class="dt">PA =</span> <span class="kw">c</span>(P1A_<span class="dv">2</span>, P2A_<span class="dv">2</span>, P3A_<span class="dv">2</span>, P4A_<span class="dv">2</span>, P5A_<span class="dv">2</span>, P6A_<span class="dv">2</span>),
                 <span class="dt">PB =</span> <span class="kw">c</span>(P1B_<span class="dv">2</span>, P2B_<span class="dv">2</span>, P3B_<span class="dv">2</span>, P4B_<span class="dv">2</span>, P5B_<span class="dv">2</span>, P6B_<span class="dv">2</span>))

<span class="kw">kable</span>(df, <span class="st">&quot;html&quot;</span>, <span class="dt">digits =</span> <span class="dv">4</span>, <span class="dt">align =</span> <span class="st">&quot;c&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">bootstrap_options =</span> <span class="kw">c</span>(<span class="st">&quot;striped&quot;</span>, <span class="st">&quot;hover&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">footnote</span>(<span class="dt">general =</span> <span class="kw">paste</span>(<span class="st">&quot;The value of the likelihood function is &quot;</span>, <span class="kw">round</span>(L, <span class="dt">digits =</span> <span class="dv">4</span>)))</code></pre></div>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
Individual
</th>
<th style="text-align:center;">
Choice
</th>
<th style="text-align:center;">
PA
</th>
<th style="text-align:center;">
PB
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.1192
</td>
<td style="text-align:center;">
0.8808
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.9820
</td>
<td style="text-align:center;">
0.0180
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
B
</td>
<td style="text-align:center;">
0.0067
</td>
<td style="text-align:center;">
0.9933
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.9991
</td>
<td style="text-align:center;">
0.0009
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
B
</td>
<td style="text-align:center;">
0.0067
</td>
<td style="text-align:center;">
0.9933
</td>
</tr>
<tr>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
B
</td>
<td style="text-align:center;">
0.7311
</td>
<td style="text-align:center;">
0.2689
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<span style="font-style: italic;">Note: </span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> The value of the likelihood function is 0.031
</td>
</tr>
</tfoot>
</table>
<p>Notice how changing the coefficients has two effects, as expected: the probabilities change and the value of the likelihood function changes too. Inspect the probabilities and the value of the likelihood function with the new coefficients. What do you notice?</p>
<p>If you are working with the R Notebook, at this point you can try changing the coefficients. Can you improve the value of the likelihood function, or maybe even make it worse?</p>
The likelihood function can be plotted as shown below. If you hover over the plot, you can see how the value of the likelihood changes as a function of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\beta\)</span>:
<div class="figure"><span id="fig:fig-likelihood-function"></span>
<div id="htmlwidget-bf553476a12fd91f0504" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-bf553476a12fd91f0504">{"x":{"visdat":{"567868af7000":["function () ","plotlyVisDat"]},"cur_data":"567868af7000","attrs":{"567868af7000":{"z":{},"x":{},"y":{},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"surface","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"x-axis (mu)"},"yaxis":{"title":"y-axis (beta)"},"zaxis":{"title":"z-axis (L)"}},"hovermode":"closest","showlegend":false,"legend":{"yanchor":"top","y":0.5}},"source":"A","config":{"cloud":false},"data":[{"colorbar":{"title":"L","ticklen":2,"len":0.5,"lenmode":"fraction","y":1,"yanchor":"top"},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"z":[[0.0125729461535497,0.0127168428937857,0.0128542560732316,0.0129850398339765,0.013109060375806,0.0132261955243578,0.0133363342560914,0.0134393761905247,0.0135352310600776,0.0136238181676198,0.0137050658414582,0.0137789108970463,0.0138452981141515,0.0139041797376102,0.0139555150091308,0.0139992697368955,0.0140354159089683,0.014063931355746,0.014084799465906,0.0140980089595044,0.0141035537210745,0.0141014326947661,0.0140916498427557,0.0140742141673451,0.014049139796356,0.014016446130616,0.0139761580515268,0.0139283061858959,0.0138729272244198,0.0138100642894113,0.0137397673465882,0.0136620936549805,0.0135771082482775,0.013484884440238,0.0133855043461283,0.0132790594115513,0.0131656509395008,0.0130453906060221,0.0129184009545107,0.0127848158584425,0.012644780942217],[0.0136413656166521,0.0138039823539243,0.0139593962437861,0.0141074264872546,0.0142479062493335,0.0143806822713386,0.0145056144265299,0.0146225752307248,0.0147314493195887,0.0148321329041454,0.0149245332157525,0.0150085679513554,0.0150841647292857,0.0151512605652247,0.0152098013772234,0.0152597415278742,0.015301043410876,0.0153336770883404,0.0153576199842567,0.0153728566385808,0.0153793785254406,0.015377183937967,0.0153662779412686,0.015346672394073,0.0153183860385595,0.015281444656919,0.0152358812921835,0.0151817365298942,0.0151190588362088,0.0150479049471063,0.0149683403024251,0.0148804395175877,0.0147842868850232,0.014679976896511,0.0145676147769561,0.0144473170194638,0.014319211911052,0.0141834400379094,0.0140401547588179,0.0138895226352118,0.0137317238063618],[0.0147858790737178,0.0149694969395379,0.0151451258619095,0.0153125435832743,0.0154715439291778,0.0156219364924551,0.0157635462448905,0.0158962130892055,0.01601979136442,0.0161341493176178,0.0162391685549461,0.0163347434843019,0.0164207807616295,0.0164971987520904,0.0165639270165846,0.0166209058332242,0.0166680857623966,0.016705427263024,0.0167329003665417,0.0167504844139899,0.0167581678604545,0.0167559481499084,0.0167438316623074,0.0167218337335883,0.0166899787480055,0.0166483003010425,0.0165968414299343,0.0165356549076662,0.0164648035951579,0.0163843608452265,0.0162944109508481,0.0161950496292163,0.0160863845321482,0.0159685357725189,0.0158416364556365,0.015705833203817,0.0155612866618961,0.0154081719710503,0.0152466791980955,0.0150770137074228,0.0148993964629186],[0.0160092880732179,0.0162164440798368,0.0164147541731193,0.0166039471002588,0.0167837700329047,0.0169539883578021,0.0171143853766045,0.0172647619287734,0.0174049359518988,0.0175347419939513,0.0176540306919088,0.0177626682309248,0.0178605357977245,0.0179475290412561,0.0180235575528104,0.0180885443768665,0.0181424255628526,0.0181851497668389,0.0182166779109279,0.0182369829067922,0.0182460494484375,0.0182438738778666,0.018230464125884,0.0182058397288359,0.0181700319206296,0.0181230837979304,0.0180650505550079,0.0179959997833043,0.0179160118294359,0.0178251802040339,0.0177236120325907,0.0176114285383177,0.0174887655459639,0.0173557739946041,0.0172126204465979,0.0170594875792724,0.0168965746454129,0.0167240978883623,0.0165422908974735,0.0163514048898247,0.0161517089045215],[0.017313924120248,0.0175474365551528,0.017771171372248,0.0179847996276143,0.0181880133724826,0.0183805255929881,0.0185620700382266,0.0187324009513819,0.0188912927194118,0.0190385394571953,0.0191739545421782,0.0192973701154134,0.0194086365645058,0.0195076220033502,0.0195942117627255,0.0196683079047946,0.0197298287733923,0.0197787085906686,0.0198148971092342,0.0198383593274291,0.0198490752737451,0.0198470398647742,0.0198322628393667,0.0198047687699666,0.0197645971503696,0.019711802557436,0.0196464548826073,0.019568639627425,0.0194784582556664,0.0193760285932022,0.0192614852652662,0.0191349801595304,0.0189966829022188,0.0188467813334929,0.0186854819675246,0.0185130104220572,0.0183296118018706,0.0181355510204258,0.0179311130440877,0.0177166030437356,0.0174923464392606],[0.0187014840903569,0.0189644795988867,0.0192166875586184,0.0194577113198386,0.0196871780321804,0.0199047387855234,0.0201100686157142,0.0203028663904309,0.0204828545915875,0.020649779011407,0.0208034083796793,0.0209435339397841,0.0210699689908084,0.021182548412549,0.0212811281893891,0.0213655849479912,0.0214358155224929,0.0214917365594506,0.0215332841731746,0.0215604136603667,0.0215730992811337,0.021571334111531,0.0215551299708133,0.0215245174245633,0.0214795458628469,0.0214202836505394,0.0213468183449966,0.0212592569743313,0.0211577263677275,0.0210423735275047,0.0209133660310496,0.0207708924493082,0.0206151627672765,0.0204464087908975,0.020264884523969,0.0200708664981284,0.0198646540387302,0.0196465694494773,0.0194169580990464,0.0191761883936478,0.0189246516205073],[0.0201728324011362,0.0204687744766738,0.0207528379487878,0.0210245469455993,0.0212834524327296,0.0215291326182047,0.0217611931961447,0.0219792674446723,0.0221830161949882,0.0223721276896759,0.0225463173490223,0.0227053274644628,0.0228489268382196,0.0229769103877896,0.0230890987332095,0.0231853377839769,0.0232654983411952,0.0233294757289471,0.0233771894671368,0.0234085829960923,0.0234236234611311,0.0234223015630956,0.0234046314785831,0.0233706508512741,0.0233204208534216,0.0232540263142463,0.0231715759097048,0.0230732024059084,0.0229590629463879,0.0228293393714619,0.0226842385562063,0.022523992751971,0.0223488599150761,0.0221591240052792,0.0219550952358678,0.0217371102568116,0.0215055322523496,0.0212607509346902,0.0210031824161896,0.0207332689434483,0.0204514784782273],[0.0217277655261578,0.022060483886814,0.0223801494712638,0.0226861939569182,0.0229780791265981,0.0232552976127926,0.0235173734522618,0.0237638624659414,0.0239943524811329,0.0242084634145493,0.0244058472359143,0.0245861878324875,0.0247492007951156,0.0248946331462019,0.0250222630293799,0.025131899379677,0.0252233815916241,0.0252965792011131,0.0253513915948888,0.0253877477594112,0.0254056060784864,0.025404954186578,0.025385808882124,0.0253482161025276,0.0252922509598225,0.0252180178333587,0.0251256505132709,0.0250153123860096,0.0248871966508795,0.024741526554387,0.0245785556272794,0.024398567907511,0.0242018781310274,0.0239888318712564,0.0237598056075666,0.0235152067027219,0.0232554732695546,0.0229810739077092,0.0226925072923829,0.0223903015985079,0.0220750137457731],[0.0233647346766479,0.0237384546568826,0.0240978638945315,0.0244422864324279,0.0247710799063819,0.0250836367185303,0.0253793849904681,0.0256577893098707,0.0259183512869345,0.0261606099391028,0.0263841419241708,0.0265885616429686,0.0267735212334083,0.0269387104777525,0.0270838566445481,0.0272087242857861,0.0273131150085444,0.0273968672386734,0.0274598559920489,0.027501992666588,0.0275232248656464,0.0275235362606586,0.0275029464979757,0.0274615111518801,0.0273993217227428,0.0273165056763102,0.0272132265172065,0.0270896838869735,0.026946113674395,0.0267827881235196,0.026600015922745,0.0263981422566277,0.0261775488007449,0.0259386536390346,0.0256819110825819,0.0254078113688447,0.0251168802208395,0.0248096782468367,0.0244868001626627,0.0241488738207375,0.0237965590324928],[0.0250805232001259,0.0254998937878177,0.0259036130754379,0.0262908800507201,0.0266609309838658,0.0270130411363307,0.0273465262171365,0.0276607435981864,0.0279550933033513,0.0282290187888709,0.0284820075348294,0.0287135914691026,0.0289233472462084,0.0291108964039422,0.029275905420541,0.0294180856944336,0.0295371934674292,0.0296330297105156,0.029705439989335,0.0297543143239362,0.0297795870546269,0.0297812367227338,0.0297592859718867,0.0297138014721508,0.0296448938659978,0.0295527177318083,0.0294374715574057,0.0292993977130935,0.0291387824108829,0.0289559556341077,0.0287512910194935,0.0285252056720379,0.0282781598918033,0.0280106567909852,0.0277232417794136,0.0274165018970077,0.0270910649726476,0.0267475985904463,0.026386808846495,0.0260094388817887,0.0256162671801718],[0.0268698766775735,0.0273399951367021,0.0277930429694694,0.0282280741264087,0.0286441837040199,0.0290405103145904,0.0294162381701877,0.0297705988888495,0.0301028730350226,0.030412391409799,0.0306985361093988,0.0309607413726143,0.0311984942395269,0.0314113350447342,0.0315988577685725,0.0317607102694281,0.0318965944192125,0.0320062661624993,0.0320895355177204,0.0321462665362794,0.0321763772325154,0.032179839494235,0.0321566789800915,0.0321069750065221,0.0320308604233388,0.0319285214734924,0.0318001976290796,0.0316461813924212,0.0314668180480914,0.0312625053491907,0.03103369311901,0.0307808827475851,0.0305046265615488,0.0302055270451945,0.0298842358908065,0.0295414528571033,0.0291779244160898,0.0287944421707105,0.0283918410284169,0.0279709971190504,0.0275328254492616],[0.0287250861288536,0.0292515162147009,0.0297593849927794,0.0302475784600145,0.0307150277548448,0.0311607123361603,0.0315836628427434,0.0319829636362908,0.0323577550359095,0.0327072352562705,0.0330306620652802,0.0333273541801286,0.0335966924228482,0.0338381206580343,0.0340511465361407,0.0342353420657776,0.0343903440377349,0.03451585432208,0.034611640057693,0.0346775337510825,0.0347134332983429,0.0347193019407777,0.0346951681611013,0.0346411255233647,0.0345573324559185,0.0344440119729409,0.0343014513264271,0.034130001577154,0.0339300770700975,0.0337021547971871,0.0334467736282066,0.0331645333891637,0.0328560937666185,0.0325221730163229,0.0321635464551076,0.0317810447162773,0.0313755517508278,0.0309480025595575,0.0304993806445636,0.0300307151726275,0.0295430778475171],[0.0306355285086483,0.0312243080552226,0.0317929765132537,0.0323402256537634,0.0328647964549548,0.0333654832648682,0.0338411376115445,0.0342906716570235,0.0347130612971376,0.0351073489141996,0.0354726457942238,0.0358081342241534,0.0361130692876365,0.0363867803801445,0.0366286724656312,0.0368382270975051,0.0370150032264334,0.0371586378164753,0.0372688462893045,0.0373454228139141,0.0373882404562878,0.0373972512001822,0.0373724858465011,0.0373140537948843,0.0372221427072005,0.0370970180487486,0.0369390224992672,0.0367485752224386,0.0365261709795758,0.0362723790706883,0.0359878420842434,0.0356732744357403,0.0353294606747627,0.034957253540512,0.0345575717469725,0.0341313974808223,0.0336797735979571,0.0332038005079932,0.0327046327402973,0.0321834751898566,0.0316415790465516],[0.0325871741879204,0.033244806284474,0.0338807370853328,0.0344934340423095,0.0350814178592239,0.0356432678445104,0.0361776268802399,0.0366832059949735,0.0371587885343161,0.0376032339290607,0.0380154810662841,0.0383945512735239,0.0387395509301546,0.0390496737232029,0.0393242025670593,0.0395625112078368,0.0397640655335092,0.0399284246104686,0.0400552414658384,0.0401442636328417,0.0401953334738674,0.0402083882927068,0.0401834602438897,0.0401206760432674,0.0400202564801158,0.039882515727215,0.0397078604417425,0.0394967886465393,0.0392498883784995,0.0389678360886131,0.038651394776661,0.0383014118428061,0.0379188166383993,0.0375046176992772,0.0370598996466644,0.0365858197435074,0.036083604097616,0.0355545435072905,0.0349999889501001,0.034421346721002,0.0338200732319393],[0.0345620787746253,0.035295498834614,0.0360056139842656,0.0366906329498079,0.0373488215997517,0.0379785097318644,0.0385780974488798,0.0391460610988844,0.0396809587635445,0.0401814352842577,0.0406462268227488,0.0410741649584273,0.0414641803298523,0.0418153058317933,0.0421266793825851,0.0423975462786877,0.0426272611545922,0.0428152895664782,0.0429612092173884,0.0430647108402218,0.0431255987526778,0.0431437910955237,0.0431193197623719,0.043052330025683,0.0429430798601307,0.0427919389609419,0.0425993874515221,0.0423660142717501,0.0420925152359322,0.0417796907476593,0.0414284431578381,0.0410397737520406,0.0406147793541052,0.0401546485346514,0.0396606574158378,0.039134165067271,0.0385766084923906,0.0379894972098214,0.0373744074399723,0.0367329759134237,0.0360668933242148],[0.0365378867750977,0.0373543955755696,0.0381460200829607,0.0389106710944584,0.0396463200885756,0.0403510077374214,0.0410228519853439,0.0416600556553553,0.0422609135526567,0.0428238190423532,0.043347270085883,0.0438298747275708,0.0442703560289014,0.0446675564534408,0.0450204417097229,0.0453281040627909,0.0455897651274154,0.0458047781573134,0.0459726298450126,0.0460929416464239,0.0461654706428161,0.0461901099508634,0.0461668886889253,0.0460959715048828,0.0459776576678905,0.0458123797234853,0.0456007017088129,0.0453433169224622,0.0450410452416977,0.0446948299788874,0.0443057342687593,0.0438749369788607,0.0434037281373022,0.0428935038745487,0.0423457608796661,0.0417620903759761,0.041144171626427,0.0404937649850301,0.0398127045172739,0.0391028902193467,0.0383662798730532],[0.0384873873909919,0.0393945377556821,0.0402752994825823,0.0411272410262761,0.0419479944218791,0.0427352658704578,0.043486845876266,0.044200618879014,0.0448745723328353,0.0455068051921631,0.0460955357731369,0.0466391089671844,0.0471360027908795,0.0475848342628578,0.0479843646043706,0.0483335037648511,0.0486313142776148,0.0488770144535006,0.0490699809219132,0.0492097505294219,0.0492960216059194,0.0493286546074735,0.0493076721436049,0.0492332583949482,0.0491057579253327,0.0489256738904255,0.0486936656434317,0.0484105457371221,0.0480772763208246,0.0476949649311278,0.0472648596760054,0.0467883438139637,0.0462669297326836,0.0457022523354652,0.0450960618485504,0.0444502160680108,0.0437666720712179,0.0430474774248043,0.0422947609282863,0.0415107229399383,0.0406976253388571],[0.0403781779691891,0.0413836004632072,0.0423612716207313,0.0433083676906107,0.044222130341313,0.0450998797367591,0.0459390271606869,0.0467370871101215,0.0474916887873096,0.0482005869286644,0.0488616719185902,0.0494729791452489,0.0500326975641407,0.0505391774435951,0.0509909372737083,0.0513866698268042,0.0517252473630246,0.0520057259791493,0.0522273491022062,0.052389550131902,0.052491954237504,0.0525343793156421,0.0525168361157619,0.0524395275398266,0.0523028471225365,0.0521073766980306,0.0518538832589471,0.0515433150140522,0.0511767966515637,0.0507556238169458,0.0502812568164369,0.0497553135609595,0.0491795617693781,0.0485559104552841,0.0478864007275306,0.0471731959414953,0.046418571245361,0.045624902573372,0.0447946551458389,0.0439303715433633,0.0430346594301092],[0.0421725074267793,0.0432836587111549,0.0443659223968206,0.0454160273030305,0.0464307678438773,0.0474070200952095,0.0483417574231602,0.0492320655667315,0.0500751570757094,0.0508683850148181,0.0516092558551598,0.0522954414843321,0.0529247902768868,0.0534953371767294,0.0540053127524445,0.0544531511951728,0.0548374972364417,0.0551572119701825,0.0554113775690099,0.0555993008897471,0.0557205159671997,0.0557747853984501,0.0557621006226034,0.0556826811031586,0.0555369724221857,0.0553256432974906,0.0550495815361201,0.0547098889401083,0.0543078751834475,0.0538450506830066,0.0533231184906259,0.052743965238912,0.0521096511793584,0.0514223993582503,0.0506845839832918,0.0498987180418488,0.0490674402399576,0.0481935013395634,0.0472797499795906,0.0463291180741237,0.0453446058879429],[0.043827388571244,0.0450512056846484,0.0462453299133119,0.0474059826962893,0.0485294487289306,0.04961209561871,0.0506503931399908,0.0516409319451077,0.0525804415976592,0.0534658078037148,0.0542940887274371,0.0550625302890826,0.0557685803551577,0.0564099017423741,0.0569843839686955,0.0574901536959724,0.0579255838192365,0.0582893011675456,0.0585801927902587,0.0587974108107675,0.0589403758370436,0.0590087789249774,0.0590025820964967,0.0589220174200296,0.0587675846661897,0.0585400475567923,0.058240428630652,0.0578700027552244,0.0574302893191775,0.0569230431475257,0.0563502441880867,0.0557140860257403,0.0550169632892515,0.0542614580241602,0.053450325114306,0.0525864768437607,0.051672966700046,0.0507129725282809,0.0497097791540449,0.0486667605999855,0.0475873620272718],[0.0452950815816446,0.0466375274250805,0.0479499302950261,0.0492279410326185,0.0504672677189666,0.0516636996249284,0.052813130833758,0.0539115833500587,0.054955229516186,0.0559404135668623,0.0568636721639919,0.0577217537661657,0.0585116367007823,0.05923054582074,0.0598759676419723,0.0604456638724096,0.060937683257024,0.061350371677257,0.0616823804562075,0.0619326728334055,0.0621005285847758,0.0621855467745579,0.0621876466365572,0.0621070665922698,0.0619443614232833,0.0617003976250544,0.0613763469788371,0.0609736783883125,0.0604941480374497,0.0599397879363736,0.0593128929325419,0.0586160062753148,0.057851903832949,0.0570235770720298,0.0561342149201882,0.0551871846434071,0.0541860118790562,0.0531343599747153,0.0520360087905896,0.0508948331295885,0.0497147809636886],[0.0465240564979927,0.0479895475081621,0.0494252417658237,0.0508261556425813,0.0521873515175421,0.0535039668336166,0.0547712429564987,0.0559845535944008,0.0571394325428093,0.0582316005274252,0.0592569909297543,0.0602117741932067,0.0610923807226673,0.0618955221069633,0.0626182105111088,0.0632577761033072,0.0638118824001414,0.0642785394319069,0.064656114648434,0.0649433415038524,0.0651393256764589,0.0652435488971224,0.0652558703764793,0.065176525837583,0.0650061241767207,0.0647456417908702,0.0643964146258137,0.0639601280143027,0.063438804388912,0.0628347889693321,0.0621507335387722,0.0613895784387985,0.0605545329261664,0.0596490540488406,0.0586768242112038,0.0576417276101816,0.0565478257343754,0.055399332127017,0.054200586620362,0.0529560292537615,0.0516701740898847],[0.0474605344804965,0.0490512523020758,0.0506131671114735,0.0521406003818383,0.053627901203378,0.055069481347927,0.056459850351071,0.057793650300015,0.059065690018987,0.0602709783512957,0.06140475624796,0.0624625273867884,0.0634400870625311,0.0643335491078819,0.0651393706262376,0.0658543743398526,0.0664757683809366,0.067001163378009,0.0674285867150977,0.0677564938669108,0.0679837767386767,0.0681097689647849,0.0681342481455323,0.0680574350261025,0.0678799896463133,0.067603004513613,0.0672279948752466,0.0667568861883887,0.0661919989092857,0.0655360307439555,0.0647920365236286,0.0639634058876993,0.0630538389752884,0.0620673203433429,0.0610080913442607,0.0598806212090297,0.0586895770925393,0.0574397933457736,0.0561362402847922,0.0547839927285284,0.0533881985763549],[0.0480506791580841,0.04976578523447,0.0514539787928618,0.05310883524687,0.054723929770755,0.056292879314589,0.0578093849790637,0.0592672743504177,0.0606605433952003,0.0619833975189307,0.0632302914019438,0.064395967239574,0.0654754910319539,0.0664642865906802,0.0673581669549799,0.0681533629383007,0.0688465485569822,0.0694348631253446,0.0699159298357219,0.0702878706772315,0.0705493175830308,0.0706994197321269,0.0707378469681574,0.070664789333696,0.0704809527542938,0.0701875509414352,0.0697862936176436,0.0692793711998933,0.0686694361090558,0.067959580903073,0.0671533134596597,0.0662545294602948,0.0652674824507804,0.0641967517744109,0.0630472086914871,0.0618239810132443,0.0605324165889451,0.059178045991689,0.0577665447512238,0.0563036954805845,0.0547953502376984],[0.0482434544890035,0.0500782502478243,0.0518890497553192,0.053668648054638,0.0554098001019823,0.0571052706243039,0.0587478848630333,0.0603305796960726,0.0618464546222414,0.0632888220912418,0.0646512566679406,0.0659276425321395,0.0671122188336999,0.0681996224474897,0.0691849277026209,0.0700636826952878,0.0708319418335833,0.0714862943053393,0.0720238882056606,0.0724424501087672,0.0727402999184096,0.0729163608818809,0.0729701647039546,0.0729018517483879,0.0727121663654386,0.0724024474336583,0.0719746142525791,0.0714311479693415,0.0707750687663728,0.0700099090784696,0.069139683145632,0.0681688532423104,0.0671022929539417,0.0659452478973894,0.0647032943027966,0.0633822958901116,0.0619883594839059,0.0605277898148971,0.0590070439557344,0.0574326858321118,0.0558113412382526],[0.0479940809865723,0.0499391855034377,0.0518643202515862,0.0537614914292208,0.0556226108728675,0.057439554457548,0.0592042221645726,0.0609085991798724,0.0625448173656297,0.0641052164372025,0.0655824041760806,0.066969315017799,0.0682592663711241,0.0694460120510312,0.0705237922424721,0.0714873794540237,0.0723321199694661,0.0730539703603155,0.0736495286824461,0.0741160600442493,0.0744515163013399,0.0746545497026947,0.0747245203843353,0.0746614976783354,0.0744662552761313,0.0741402603549687,0.0736856568439958,0.0731052430711799,0.0724024440931439,0.0715812790664153,0.0706463240698129,0.0696026708331008,0.0684558818660712,0.0672119425143793,0.0658772104933473,0.0644583634682777,0.0629623452593874,0.0613963112512187,0.0597675735803856,0.0580835466619555,0.0563516935940051],[0.0472679105847473,0.0493085587330954,0.051334384861708,0.0533366331823254,0.0553063829891437,0.0572346159195776,0.0591122859975881,0.0609303916758059,0.0626800490529327,0.0643525654157307,0.0659395122407735,0.0674327967902463,0.0688247314484042,0.0701080999705303,0.0712762198538564,0.0723230000891745,0.0732429936118544,0.0740314438405942,0.0746843247702442,0.0751983741701227,0.0755711195299846,0.0758008964907402,0.0758868595946685,0.0758289852887381,0.0756280672132588,0.0752857039049973,0.0748042791377122,0.0741869352124672,0.0734375395938213,0.0725606453649219,0.0715614460436008,0.0704457253618718,0.0692198026619855,0.0678904746027788,0.0664649539000125,0.0649508058434449,0.0633558833414458,0.0616882612411162,0.059956170658442,0.0581679340294455,0.0563319015602772],[0.0460444133790247,0.0481600041753941,0.0502669502099839,0.0523558043939817,0.0544168672748755,0.0564402628775338,0.0584160188471224,0.0603341499564049,0.0621847439698676,0.0639580488033507,0.065644559881595,0.0672351065780513,0.0687209366218379,0.0700937973758249,0.0713460129271066,0.072470555985817,0.0734611136592828,0.0743121462545025,0.0750189383612395,0.0755776415787613,0.0759853083693927,0.0762399166494084,0.0763403848600903,0.0762865773967204,0.0760793004085407,0.0757202881160246,0.075212179920949,0.0745584887076645,0.0737635608486634,0.0728325285322838,0.0717712551235981,0.0705862743498629,0.0692847241682924,0.0678742762255228,0.0663630618544467,0.0647595955748633,0.063072697069679,0.0613114125985426,0.0594849367864409,0.0576025356867994,0.055673471968161],[0.044320849053175,0.0464848873437008,0.0486472693228351,0.0507979765751564,0.0529266353655405,0.0550225999846965,0.0570750423612248,0.0590730468608134,0.0610057090785742,0.0628622373362191,0.0646320555240281,0.0663049058800972,0.0678709502773399,0.0693208685927596,0.0706459527635963,0.0718381951905335,0.0728903702280708,0.0737961076048,0.0745499567395241,0.0751474410603991,0.0755851015906718,0.0758605292329678,0.0759723853610791,0.0759204105103405,0.0757054211414104,0.0753292946340986,0.0747949428443938,0.0741062747258224,0.0732681486727072,0.0722863153851054,0.0711673521808281,0.0699185897870132,0.0685480327306961,0.0670642745136046,0.065476408800353,0.0637939378711536,0.0620266795903949,0.0601846741216626,0.058278091579146,0.0563171417463805,0.054311986917751],[0.0421151131282191,0.0442956781201394,0.0464820315572662,0.0486637531953316,0.0508299530254413,0.0529693601432347,0.0550704202779383,0.0571214007983499,0.0591105018372328,0.0610259720235539,0.062856227187514,0.0645899703097739,0.0662163109262886,0.067724882175518,0.0691059536863896,0.0703505385532486,0.0714504927272593,0.0723986052705495,0.0731886780672669,0.0738155937613296,0.074275370890078,0.0745652054017994,0.0746834979783502,0.0746298668266795,0.0744051458497076,0.0740113683524208,0.0734517366780637,0.0727305783970159,0.0718532898827828,0.0708262683014211,0.0696568332091257,0.0683531390947217,0.0669240803171996,0.0653791899716994,0.0637285342697032,0.0619826040405848,0.0601522049527413,0.0582483480146028,0.0562821418508062,0.0542646881591824,0.0522069816428417],[0.0394672374421515,0.0416280709698829,0.0438021145280465,0.045978758355428,0.0481468039667085,0.0502945557128963,0.0524099237236818,0.0544805370139411,0.0564938652838652,0.0584373477140413,0.0602985268599103,0.0620651855902864,0.0637254848970005,0.0652681003310776,0.0666823547977736,0.0679583454695574,0.069087062652633,0.0700604985673781,0.0708717441733538,0.0715150723812687,0.0719860062423583,0.0722813709839633,0.0723993290618506,0.0723393977176156,0.0721024488556306,0.0716906913806413,0.0711076364565473,0.0703580464517842,0.0694478686201941,0.0683841548222161,0.0671749688143677,0.065829282821044,0.0643568652484111,0.0627681615035326,0.0610741699418791,0.0592863149832378,0.0574163194109881,0.0554760778050372,0.0534775329575403,0.0514325569868122,0.0493528387031074],[0.0364391122244465,0.0385413458147477,0.0406636235072107,0.0427953870118334,0.0449253754960367,0.0470417164202456,0.0491320306110644,0.051183550414315,0.0531832494280579,0.0551179819955427,0.0569746303499089,0.0587402570557773,0.0604022601959965,0.061948528611755,0.0633675944264359,0.0646487800715357,0.065782337088271,0.0667595741006862,0.0675729715426178,0.0682162809672704,0.0686846070680917,0.0689744708851575,0.0690838530531238,0.0690122163546717,0.0687605072662783,0.0683311366098067,0.0677279398425787,0.0669561179194423,0.0660221600327996,0.0649337498715788,0.0636996573299871,0.0623296178353489,0.0608342016468486,0.0592246756007199,0.0575128598413035,0.0557109820820685,0.053831531888473,0.0518871173691882,0.0498903265088194,0.0478535951799965,0.0457890836425731],[0.0331121905278487,0.0351166299773018,0.0371467785463109,0.0391923788857467,0.0412423737587715,0.0432849926258922,0.0453078551795502,0.0472980908366594,0.0492424727619665,0.0511275645740442,0.052939877493159,0.0546660353398635,0.0562929444977429,0.0578079657246558,0.0591990845435031,0.0604550768731317,0.0615656665768663,0.0625216717118945,0.0633151364558324,0.0639394459628105,0.0643894217530354,0.0646613956571032,0.0647532608072482,0.0646644986783082,0.0643961817163287,0.0639509516365734,0.0633329740093213,0.0625478702657251,0.0616026287327321,0.0605054967326781,0.0592658561486271,0.0578940851521037,0.0564014090092708,0.054799743021233,0.0531015307129967,0.0513195803653099,0.0494669028881274,0.0475565538699675,0.0456014824119338,0.0436143890781152,0.0416075949759613],[0.0295832119232955,0.0314529878463191,0.0333524579681443,0.0352719008997357,0.0372007258211612,0.0391275517707468,0.0410403061330303,0.0429263415934088,0.044772570305815,0.0465656135001665,0.0482919642567023,0.0499381607130052,0.0514909665643994,0.052937555386171,0.0542656950613082,0.0554639284520946,0.0565217464164354,0.0574297493449611,0.0581797935833097,0.0587651194018388,0.0591804575745163,0.0594221121181006,0.0594880173067347,0.0593777676976724,0.0590926205608738,0.0586354707772117,0.0580107989352179,0.0572245939933439,0.056284252463677,0.0551984565960906,0.053977034483887,0.0526308053613665,0.0511714136123501,0.0496111551522603,0.0479627998845527,0.0462394138684219,0.0444541846754977,0.0426202531684075,0.0407505546157197,0.0388576716798494,0.0369537013921285],[0.0259582885578824,0.0276615851338816,0.0293965328570581,0.0311541457720406,0.0329245360217289,0.0346969838163643,0.0364600280885478,0.0382015774154077,0.0399090402008381,0.0415694725083632,0.0431697413401242,0.0446967005924602,0.0461373764066072,0.0474791581964688,0.0487099912946459,0.0498185669304541,0.0507945051530677,0.0516285263480693,0.0523126071700491,0.0528401170253251,0.0532059316794423,0.0534065211204425,0.0534400094625964,0.0533062054037863,0.0530066025272564,0.0525443495372317,0.0519241913094277,0.0511523823937383,0.0502365753012292,0.0491856865177152,0.0480097436923301,0.0467197178369014,0.0453273446310846,0.0438449390549176,0.0422852075658923,0.0406610619080137,0.0389854383963325,0.0372711261766167,0.0355306075336342,0.0337759128324451,0.0320184921456784],[0.0223459621969506,0.0238584791684245,0.0254024651912326,0.0269698188165247,0.0285515465662073,0.030137822883781,0.0317180712795647,0.0332810665595055,0.0348150574005546,0.0363079078787041,0.0377472558918877,0.0391206857751949,0.0404159118076525,0.0416209687855944,0.0427244054133318,0.0437154759604967,0.044584325475836,0.0453221638426605,0.0459214241184253,0.0463759009197714,0.0466808650871918,0.0468331514755108,0.0468312174461969,0.046675170458127,0.0463667640333945,0.0459093622799213,0.0453078740477116,0.0445686586459803,0.0436994058218944,0.0427089933700215,0.0416073262817755,0.0404051617394129,0.0391139244995198,0.0377455172935666,0.0363121308019938,0.0348260575437808,0.0332995136813888,0.0317444722916392,0.030172511119924,0.028594677243443,0.0270213704447308],[0.0188499995300901,0.0201568027763649,0.0214929157272587,0.0228512140719371,0.0242237336468425,0.0256017209359549,0.0269757042066551,0.0283355854109449,0.0296707523512959,0.0309702099359294,0.0322227286544433,0.0334170077194264,0.0345418496733039,0.0355863426831616,0.0365400462697713,0.0373931758678774,0.0381367814159422,0.0387629151419037,0.0392647838566686,0.0396368813903819,0.0398750973006241,0.0399767986306016,0.0399408822751288,0.0397677963918708,0.0394595302387759,0.039019572786342,0.0384528414045928,0.0377655828196723,0.0369652493372207,0.0360603540077069,0.0350603089378285,0.0339752513149461,0.0328158618996815,0.0315931807552258,0.0303184248286165,0.0290028116945672,0.0276573933377021,0.0262929033101092,0.024919619986713,0.0235472479809517,0.0221848191071067],[0.0155627081512939,0.0166591877367666,0.0177812564216867,0.0189228056548869,0.0200769758551638,0.0212361988715033,0.0223922595079809,0.0235363763718479,0.0246593017021372,0.025751439184249,0.0268029780774942,0.0278040413056385,0.0287448445161151,0.0296158625340699,0.0304079991545541,0.0311127558593016,0.0317223948384939,0.032230091661325,0.0326300730828532,0.0329177358004453,0.0330897424735202,0.0331440919782492,0.0330801616585954,0.0328987202233191,0.0326019108864137,0.0321932053135371,0.0316773298760451,0.0310601665855019,0.0303486318473146,0.0295505368008074,0.0286744334808238,0.0277294513279303,0.0267251286850418,0.0256712438516353,0.0245776500351028,0.0234541181620365,0.0223101910159415,0.0211550515815995,0.0199974078316152,0.0188453955192647,0.0177064998736938],[0.0125594359243261,0.0134512093096169,0.0143638861072045,0.0152923659833069,0.0162309125822285,0.0171731895716909,0.018112313356096,0.0190409227229543,0.0199512651453461,0.0208352988716767,0.021684809315521,0.0224915376395232,0.0232473188375553,0.0239442260895089,0.0245747177236805,0.0251317828008534,0.0256090811557008,0.0260010737126913,0.0263031390451827,0.0265116724689391,0.026624164446586,0.0266392557099304,0.0265567672564726,0.0263777042115095,0.0261042334294517,0.0257396355959179,0.0252882334440624,0.0247552984749188,0.0241469392374286,0.0234699747510925,0.0227317970228849,0.0219402268093968,0.0211033668037187,0.0202294562919494,0.0193267310420661,0.0184032917804534,0.0174669841057156,0.0165252921153972,0.0155852474097077,0.0146533545171462,0.0137355331873336],[0.00989471316832134,0.0105964664564966,0.0113141338650325,0.0120435786754684,0.0127801558862995,0.0135187431082456,0.0142537851919146,0.0149793527653578,0.0156892143981335,0.0163769216070141,0.0170359053960362,0.0176595825034245,0.018241469035721,0.0187752987320452,0.0192551427451184,0.0196755275745172,0.020031547661579,0.0203189691687394,0.0205343216261163,0.020674974434171,0.0207391956542434,0.0207261910815071,0.0206361222529047,0.0204701027654552,0.0202301730333917,0.0199192543593952,0.0195410838996391,0.019100132731054,0.0186015097535513,0.0180508545577918,0.017454222645991,0.0168179665030517,0.0161486159801045,0.0154527612821014,0.0147369415618423,0.0140075417362689,0.0132706996820214,0.0125322254627906,0.0117975337175118,0.0110715898209156,0.0103588699384716],[0.00760028049518794,0.00813370742846546,0.00867835531248009,0.0092309767685649,0.00978794262012305,0.0103452682606583,0.0108986506246642,0.0114435158097736,0.0119750770326666,0.0124884022073553,0.0129784900287144,0.0134403530452452,0.0138691058334699,0.0142600560630624,0.0146087959870404,0.0149112917231533,0.0151639676254783,0.0153637830889116,0.0155082992876242,0.0155957336191961,0.015625,0.0155957336191961,0.0155082992876242,0.0153637830889116,0.0151639676254783,0.0149112917231533,0.0146087959870404,0.0142600560630624,0.01386910583347,0.0134403530452452,0.0129784900287144,0.0124884022073553,0.0119750770326667,0.0114435158097736,0.0108986506246642,0.0103452682606583,0.00978794262012306,0.0092309767685649,0.00867835531248009,0.00813370742846546,0.00760028049518794]],"x":[-1,-0.95,-0.9,-0.85,-0.8,-0.75,-0.7,-0.65,-0.6,-0.55,-0.5,-0.45,-0.4,-0.35,-0.3,-0.25,-0.2,-0.15,-0.1,-0.0499999999999999,0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1],"y":[-2,-1.95,-1.9,-1.85,-1.8,-1.75,-1.7,-1.65,-1.6,-1.55,-1.5,-1.45,-1.4,-1.35,-1.3,-1.25,-1.2,-1.15,-1.1,-1.05,-1,-0.95,-0.9,-0.85,-0.8,-0.75,-0.7,-0.65,-0.6,-0.55,-0.5,-0.45,-0.4,-0.35,-0.3,-0.25,-0.2,-0.15,-0.0999999999999999,-0.0499999999999998,0],"type":"surface","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p class="caption">
Figure 5.1: Likelihood function for toy dataset
</p>
</div>
<p>From Figure <a href="chapter-3.html#fig:fig-evi-distribution">4.1</a> we can see that the approximate values of the coefficients that maximize the likelihood function are <span class="math inline">\(\mu=0.10\)</span> and <span class="math inline">\(\beta=-0.65\)</span>. If we use these coefficients to calculate the logit probabilities, we can compare to the probabilities of Experiments 1 and 2:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Approximate values that maximize the likelihood function.</span>
mu &lt;-<span class="st"> </span><span class="fl">0.10</span>
beta &lt;-<span class="st"> </span><span class="op">-</span><span class="fl">0.65</span>

P1A_<span class="dv">3</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">1</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">1</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">1</span>])))
P1B_<span class="dv">3</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">1</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">1</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">1</span>])))
P2A_<span class="dv">3</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">2</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">2</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">2</span>])))
P2B_<span class="dv">3</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">2</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">2</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">2</span>])))
P3A_<span class="dv">3</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">3</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">3</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">3</span>])))
P3B_<span class="dv">3</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">3</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">3</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">3</span>])))
P4A_<span class="dv">3</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">4</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">4</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">4</span>])))
P4B_<span class="dv">3</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">4</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">4</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">4</span>])))
P5A_<span class="dv">3</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">5</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">5</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">5</span>])))
P5B_<span class="dv">3</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">5</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">5</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">5</span>])))
P6A_<span class="dv">3</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">6</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">6</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">6</span>])))
P6B_<span class="dv">3</span> &lt;-<span class="st"> </span>(<span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">6</span>])<span class="op">/</span>(<span class="kw">exp</span>(beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiA[<span class="dv">6</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(mu <span class="op">+</span><span class="st"> </span>beta <span class="op">*</span><span class="st"> </span>ts<span class="op">$</span>xiB[<span class="dv">6</span>])))
  
L &lt;-<span class="st">  </span>P1A_<span class="dv">3</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>P1B_<span class="dv">3</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P2A_<span class="dv">3</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>P2B_<span class="dv">3</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P3A_<span class="dv">3</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>P3B_<span class="dv">3</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P4A_<span class="dv">3</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">4</span>] <span class="op">*</span><span class="st"> </span>P4B_<span class="dv">3</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">4</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P5A_<span class="dv">3</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">5</span>] <span class="op">*</span><span class="st"> </span>P5B_<span class="dv">3</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">5</span>] <span class="op">*</span><span class="st"> </span>
<span class="st">  </span>P6A_<span class="dv">3</span><span class="op">^</span>ts<span class="op">$</span>yiA[<span class="dv">6</span>] <span class="op">*</span><span class="st"> </span>P6B_<span class="dv">3</span><span class="op">^</span>ts<span class="op">$</span>yiB[<span class="dv">6</span>] 

<span class="co"># Create data frame to tabulate results:</span>
df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Individual =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>),
                 <span class="dt">Choice =</span> <span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;B&quot;</span>),
                 <span class="dt">PA_1 =</span> <span class="kw">c</span>(P1A_<span class="dv">1</span>, P2A_<span class="dv">1</span>, P3A_<span class="dv">1</span>, P4A_<span class="dv">1</span>, P5A_<span class="dv">1</span>, P6A_<span class="dv">1</span>),
                 <span class="dt">PB_1 =</span> <span class="kw">c</span>(P1B_<span class="dv">1</span>, P2B_<span class="dv">1</span>, P3B_<span class="dv">1</span>, P4B_<span class="dv">1</span>, P5B_<span class="dv">1</span>, P6B_<span class="dv">1</span>),
                 <span class="dt">PA_1 =</span> <span class="kw">c</span>(P1A_<span class="dv">2</span>, P2A_<span class="dv">2</span>, P3A_<span class="dv">2</span>, P4A_<span class="dv">2</span>, P5A_<span class="dv">2</span>, P6A_<span class="dv">2</span>),
                 <span class="dt">PB_1 =</span> <span class="kw">c</span>(P1B_<span class="dv">2</span>, P2B_<span class="dv">2</span>, P3B_<span class="dv">2</span>, P4B_<span class="dv">2</span>, P5B_<span class="dv">2</span>, P6B_<span class="dv">2</span>),
                 <span class="dt">PA_1 =</span> <span class="kw">c</span>(P1A_<span class="dv">3</span>, P2A_<span class="dv">3</span>, P3A_<span class="dv">3</span>, P4A_<span class="dv">3</span>, P5A_<span class="dv">3</span>, P6A_<span class="dv">3</span>),
                 <span class="dt">PB_1 =</span> <span class="kw">c</span>(P1B_<span class="dv">3</span>, P2B_<span class="dv">3</span>, P3B_<span class="dv">3</span>, P4B_<span class="dv">3</span>, P5B_<span class="dv">3</span>, P6B_<span class="dv">3</span>))

<span class="kw">kable</span>(df, <span class="st">&quot;html&quot;</span>, <span class="dt">digits =</span> <span class="dv">4</span>, 
      <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;Individual&quot;</span>, <span class="st">&quot;Choice&quot;</span>, <span class="st">&quot;PA&quot;</span>, <span class="st">&quot;PB&quot;</span>, <span class="st">&quot;PA&quot;</span>, <span class="st">&quot;PB&quot;</span>, <span class="st">&quot;PA&quot;</span>, <span class="st">&quot;PB&quot;</span>),
      <span class="dt">align =</span> <span class="st">&quot;c&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">bootstrap_options =</span> <span class="kw">c</span>(<span class="st">&quot;striped&quot;</span>, <span class="st">&quot;hover&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_header_above</span>(<span class="kw">c</span>(<span class="st">&quot; &quot;</span> =<span class="st"> </span><span class="dv">1</span>, <span class="st">&quot; &quot;</span> =<span class="st"> </span><span class="dv">1</span>, <span class="st">&quot;Experiment 1&quot;</span> =<span class="st"> </span><span class="dv">2</span>, <span class="st">&quot;Experiment 2&quot;</span> =<span class="st"> </span><span class="dv">2</span>, <span class="st">&quot;Approx Max Likelihood&quot;</span> =<span class="st"> </span><span class="dv">2</span>))</code></pre></div>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Experiment 1
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Experiment 2
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Approx Max Likelihood
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Individual
</th>
<th style="text-align:center;">
Choice
</th>
<th style="text-align:center;">
PA
</th>
<th style="text-align:center;">
PB
</th>
<th style="text-align:center;">
PA
</th>
<th style="text-align:center;">
PB
</th>
<th style="text-align:center;">
PA
</th>
<th style="text-align:center;">
PB
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.1192
</td>
<td style="text-align:center;">
0.8808
</td>
<td style="text-align:center;">
0.3208
</td>
<td style="text-align:center;">
0.6792
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.9820
</td>
<td style="text-align:center;">
0.0180
</td>
<td style="text-align:center;">
0.8641
</td>
<td style="text-align:center;">
0.1359
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
B
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.0067
</td>
<td style="text-align:center;">
0.9933
</td>
<td style="text-align:center;">
0.1141
</td>
<td style="text-align:center;">
0.8859
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
A
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.9991
</td>
<td style="text-align:center;">
0.0009
</td>
<td style="text-align:center;">
0.9589
</td>
<td style="text-align:center;">
0.0411
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
B
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.0067
</td>
<td style="text-align:center;">
0.9933
</td>
<td style="text-align:center;">
0.1141
</td>
<td style="text-align:center;">
0.8859
</td>
</tr>
<tr>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
B
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.5
</td>
<td style="text-align:center;">
0.7311
</td>
<td style="text-align:center;">
0.2689
</td>
<td style="text-align:center;">
0.6341
</td>
<td style="text-align:center;">
0.3659
</td>
</tr>
</tbody>
</table>
<p>Maximizing the likelihood is a useful criterion to estimate the coefficients of the models, since this criterion provides the optimal probabilities of the right alternative being chosen - which does not necessarily mean that those probabilities will be high!</p>
<p>In this toy example we “solved” the problem of maximizing the likelihood by hand. This is rather difficult, unfeasible even, in most applied situations with large samples and/or more than one variable. Fortunately, there are a number of numerical algorithms that can be used to maximize the likelihood. We will not discuss this in detail, but interested readers can consult Train [<span class="citation">Train (<a href="#ref-Train2009discrete">2009</a>)</span>; Section 3.7] for details. The <code>mlogit</code> package imports the package <code>maxLik</code> <span class="citation">(Henningsen and Toomet <a href="#ref-Henningsen2011maxlik">2011</a>)</span>, which implements canonical algorithms including <a href="https://en.wikipedia.org/wiki/Newton%27s_method">Newton-Raphson</a>, the Berndt–Hall–Hall–Hausman (or <a href="https://en.wikipedia.org/wiki/Berndt-Hall-Hall-Hausman_algorithm">BHHH</a>), and the Broyden–Fletcher–Goldfarb–Shanno (or <a href="https://en.wikipedia.org/wiki/Broyden-Fletcher-Goldfarb-Shanno_algorithm">BFGS</a>) algorithm.</p>
<p>In practice, the algorithms above maximize not the likelihood function, but a transformation thereof, called the <em>log-likelihood</em>: <span class="math display">\[
l = \sum_{i=n}^N\sum_{j=1}^J y_{ij}log(P_{ij})
\]</span> Since the likelihood function is bound between zero and one, the log-likelihood is bound between minus infinity and zero. The value of the maximized log-likelihood function provides a useful diagnostic to compare models, since higher values are indicative of a better model. Several statistical tests (such as the likelihood ratio) can be used to test the hypothesis that a model is a significant improvement over other, and are thus useful for model selection purposes. Before these diagnostics, lets see how multinomial logit models are estimated using <code>mlogit</code>.</p>
</div>
<div id="example-a-logit-model-of-mode-choice" class="section level2">
<h2><span class="header-section-number">5.9</span> Example: A logit model of mode choice</h2>
<p>Coming back to the transportation mode choice dataset, we already defined some formulas (i.e., utility functions) that we can use to estimate a model.</p>
<p>The function to estimate a model is <code>mlogit()</code>. This function requires at least two arguments: an <code>mFormula</code> object and a dataset. We can verify that the formulas we created above are of this class:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(f1)</code></pre></div>
<pre><code>## [1] &quot;mFormula&quot; &quot;Formula&quot;  &quot;formula&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(f2)</code></pre></div>
<pre><code>## [1] &quot;mFormula&quot; &quot;Formula&quot;  &quot;formula&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(f3)</code></pre></div>
<pre><code>## [1] &quot;mFormula&quot; &quot;Formula&quot;  &quot;formula&quot;</code></pre>
<p>The value (output) of the function can be named and saved to an object for further analysis or post-estimation processing. Begin by estimating the</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model1 &lt;-<span class="st"> </span><span class="kw">mlogit</span>(f1, mc_commute)
<span class="kw">summary</span>(model1)</code></pre></div>
<pre><code>## 
## Call:
## mlogit(formula = choice ~ time, data = mc_commute, method = &quot;nr&quot;, 
##     print.level = 0)
## 
## Frequencies of alternatives:
##    Cycle     Walk      HSR      Car 
## 0.034884 0.516715 0.244186 0.204215 
## 
## nr method
## 6 iterations, 0h:0m:0s 
## g&#39;(-H)^-1g = 4.14E-05 
## successive function values within tolerance limits 
## 
## Coefficients :
##                     Estimate  Std. Error z-value  Pr(&gt;|z|)    
## Walk:(intercept)  2.8006e+00  1.5419e-01 18.1632 &lt; 2.2e-16 ***
## HSR:(intercept)   1.7270e+00  1.5493e-01 11.1471 &lt; 2.2e-16 ***
## Car:(intercept)   1.8978e+00  1.6151e-01 11.7506 &lt; 2.2e-16 ***
## time             -9.2134e-06  1.0585e-06 -8.7037 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Log-Likelihood: -1509.6
## McFadden R^2:  0.026441 
## Likelihood ratio test : chisq = 82 (p.value = &lt; 2.22e-16)</code></pre>
<p>The output of the function includes the estimated frequencies of alternatives in addition to information about the optimization procedure. For instance, the message “successive function values within tolerance limits” indicates that the algorithm converged normally.</p>
<p>The output also reports the estimated values of the coefficients, along with standard errors, z-values, and p-values. Recall that the null hypothesis in this case is that the coefficient is zero. Small p-values can be used to reject the null hypothesis. In the present case, the null hypothesis can be comfortably rejected.</p>
<p>This simple model includes three alternative-specific constants and one alternative-specific variable with a generic coefficient. The signs of the coefficients are informative. Since the reference mode is “Cycle”, the positive values of the constants indicate that, other things being equal, cycling is the least preferred mode, followed by HSR and then Car. The most preferred mode (again, other things being equal), is Walk. This is verified from the estimated frequencies of the modes.</p>
<p>The negative coefficient for time indicates that time is a “cost”, in other words, the utility tends to decline with increasing travel times. This means that modes that tend to be slower will have lower utilities.</p>
<p>Finally, the maximized value of the log-likelihood function is reported, along with two diagnostics, McFadden R^2 (in reality <span class="math inline">\(\rho^2\)</span>) and a likelihood ratio tests. We will come back to these diagnostics below, but first, lets estimate a model using the second formula.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model2 &lt;-<span class="st"> </span><span class="kw">mlogit</span>(f2, mc_commute)
<span class="kw">summary</span>(model2)</code></pre></div>
<pre><code>## 
## Call:
## mlogit(formula = choice ~ time | age, data = mc_commute, method = &quot;nr&quot;, 
##     print.level = 0)
## 
## Frequencies of alternatives:
##    Cycle     Walk      HSR      Car 
## 0.034884 0.516715 0.244186 0.204215 
## 
## nr method
## 6 iterations, 0h:0m:0s 
## g&#39;(-H)^-1g = 4.3E-05 
## successive function values within tolerance limits 
## 
## Coefficients :
##                     Estimate  Std. Error z-value  Pr(&gt;|z|)    
## Walk:(intercept)  4.7672e+00  6.9102e-01  6.8988 5.245e-12 ***
## HSR:(intercept)   1.9714e+00  6.5141e-01  3.0263  0.002476 ** 
## Car:(intercept)   1.0572e+00  6.4186e-01  1.6471  0.099543 .  
## time             -9.0888e-06  1.0778e-06 -8.4326 &lt; 2.2e-16 ***
## Walk:age         -9.0142e-02  2.9816e-02 -3.0233  0.002501 ** 
## HSR:age          -1.0414e-02  2.7417e-02 -0.3798  0.704064    
## Car:age           3.7357e-02  2.6923e-02  1.3876  0.165271    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Log-Likelihood: -1480.4
## McFadden R^2:  0.045309 
## Likelihood ratio test : chisq = 140.51 (p.value = &lt; 2.22e-16)</code></pre>
<p>Now there is an individual-specific variable in the model (i.e., age). Only one of those coefficients is significant at conventional levels (i.e., <span class="math inline">\(p&lt;0.05\)</span>), and it is negative. Since the reference is “Cycle”, a negative value indicates that the utility of walking declines with age with respect to the utility of cycling. Two other coefficients for age (in the utility of HSR and CAR) are not significantly different from zero, meaning that age does not change the utility of travel by HSR and Car with respect to Cycle.</p>
<p>Note that it is possible to select the reference level for the utilities when estimating the model. For example, lets reestimate the model above, but now using the utility of Walk as the reference:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model2 &lt;-<span class="st"> </span><span class="kw">mlogit</span>(f2, mc_commute, <span class="dt">reflevel =</span> <span class="st">&quot;Walk&quot;</span>)
<span class="kw">summary</span>(model2)</code></pre></div>
<pre><code>## 
## Call:
## mlogit(formula = choice ~ time | age, data = mc_commute, reflevel = &quot;Walk&quot;, 
##     method = &quot;nr&quot;, print.level = 0)
## 
## Frequencies of alternatives:
##     Walk    Cycle      HSR      Car 
## 0.516715 0.034884 0.244186 0.204215 
## 
## nr method
## 6 iterations, 0h:0m:0s 
## g&#39;(-H)^-1g = 4.3E-05 
## successive function values within tolerance limits 
## 
## Coefficients :
##                      Estimate  Std. Error z-value  Pr(&gt;|z|)    
## Cycle:(intercept) -4.7672e+00  6.9102e-01 -6.8988 5.245e-12 ***
## HSR:(intercept)   -2.7959e+00  4.1947e-01 -6.6652 2.644e-11 ***
## Car:(intercept)   -3.7100e+00  4.1768e-01 -8.8825 &lt; 2.2e-16 ***
## time              -9.0888e-06  1.0778e-06 -8.4326 &lt; 2.2e-16 ***
## Cycle:age          9.0142e-02  2.9816e-02  3.0233  0.002501 ** 
## HSR:age            7.9728e-02  1.9135e-02  4.1666 3.091e-05 ***
## Car:age            1.2750e-01  1.8769e-02  6.7931 1.098e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Log-Likelihood: -1480.4
## McFadden R^2:  0.045309 
## Likelihood ratio test : chisq = 140.51 (p.value = &lt; 2.22e-16)</code></pre>
<p>Now all age-related coefficients are significant! Whereas some of them are not significantly different with respect to each other as seen above (e.g. Cycle and HSR), the are <em>all</em> significantly different from the reference. Since the coefficients are positive, this indicates that the utilities of cycling, using HSR, and traveling by car all increase with age <em>with respect to walking</em>.</p>
<p>The value of the maximized log-likelihood and other diagnostics are identical, irrespective of which mode is selected as a utility. In essence, the models are the same, but they provide a different perspective on how some coefficients relate to each other across alternatives.</p>
<p>We can visually explore how the probability of choosing different modes varies with age. First summarize the age variable:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(mc_commute<span class="op">$</span>age)</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   17.00   20.00   21.00   22.08   23.00   60.00</code></pre>
<p>Copy the dataframe used to estimate the model, but only enough columns to explore an age range of 10 years, say from 17 to 26. Since there are four alternatives, this means that we need fourty rows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mc_commute_predict &lt;-<span class="st"> </span>mc_commute[<span class="dv">1</span><span class="op">:</span><span class="dv">40</span>,]</code></pre></div>
<p>Replace the age variable by values for ages 17 to 26:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mc_commute_predict<span class="op">$</span>age &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">17</span><span class="op">:</span><span class="dv">26</span>), <span class="dt">each =</span> <span class="dv">4</span>)</code></pre></div>
<p>Replace time by median travel time:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mc_commute_predict<span class="op">$</span>time &lt;-<span class="st"> </span><span class="kw">median</span>(mc_commute<span class="op">$</span>time)</code></pre></div>
<p>Next, predict the probabilities using the <code>predict()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">probs &lt;-<span class="st"> </span><span class="kw">predict</span>(model2, <span class="dt">newdata =</span> mc_commute_predict)</code></pre></div>
<p>The value (output) of <code>predict</code> is a 10-by-4 matrix that contains the probability for ten age values (i.e., 16, 17, 18, …, 26), and four modes (Walk, Cycle, HSR, Car). To facilitate plotting, we add the age values and then reshape that 10-by-4 matrix as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">probs &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">age =</span> <span class="kw">c</span>(<span class="dv">17</span><span class="op">:</span><span class="dv">26</span>), probs) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">gather</span>(<span class="dt">key =</span> <span class="st">&quot;Mode&quot;</span>, <span class="dt">value =</span> <span class="st">&quot;Probability&quot;</span>, <span class="op">-</span>age)</code></pre></div>
<p>By “gathering” the probabilities, now the data frame has one column with the mode and one column with the probability. We can then plot:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> probs, <span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> Probability, <span class="dt">color =</span> Mode)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-71-1.png" width="672" /></p>
<p>We can see that the probability of walking (for a trip that takes the median duration in the sample) declines with age. The probability of using the three other modes increases with age, but more rapidly for car than for transit or cycling.</p>
</div>
<div id="comparing-models-mcfaddens-rho2" class="section level2">
<h2><span class="header-section-number">5.10</span> Comparing models: McFadden’s <span class="math inline">\(\rho^2\)</span></h2>
<p>The log-likelihood reported in the summary of the model is useful as a measure of goodness of fit. Recall that the likelihood of this model is bounded between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>, and therefore the log-likelihood is bounded at the upper end by <span class="math inline">\(0\)</span> (it is minus infinity at the lower end). We also know that higher values of the likelihood represent better fits.</p>
<p>One simple diagnostic to compare the fit of models is McFadden’s <span class="math inline">\(\rho^2\)</span>. This summary diagnostic is defined as follows: <span class="math display">\[
\rho^2 = 1 - \frac{l^*}{l_0}
\]</span> where <span class="math inline">\(l^*\)</span> is the value of the maximized log-likelihood and <span class="math inline">\(l_0\)</span> is the value of the log-likelihood of a null model (perhaps without constants, or a constants only model). If the model is uninformative, its log-likelihood will tend to the likelihood of the null model. In this case <span class="math inline">\(l^*/l_0\)</span> tends to one and therefore <span class="math inline">\(\rho^2\)</span> tends to zero. If the maximized log-likelihood of the model tends to 0 (the upper limit for the log-likelihood function), <span class="math inline">\(\rho^2\)</span> tends to one.</p>
<p>Although <span class="math inline">\(\rho^2\)</span> is bounded between zero and one, similar to the coefficient of determination <span class="math inline">\(R^2\)</span> in regression analysis, its interpretation is <em>not</em> the same as for <span class="math inline">\(R^2\)</span>. Whereas <span class="math inline">\(R^2\)</span> is interpreted as the proportion of variance explained by the model, <span class="math inline">\(\rho^2\)</span> lacks such an interpretation. Also, the values of <span class="math inline">\(\rho^2\)</span> tend to be lower, and values of <span class="math inline">\(0.4\)</span> are considered very good fits. The main utility of McFadden’s <span class="math inline">\(\rho^2\)</span> is as a quick way of comparing the relative fit of different models, rather than assessing the fit against an absolute value of goodness of fit.</p>
</div>
<div id="comparing-models-the-likelihood-ratio-test" class="section level2">
<h2><span class="header-section-number">5.11</span> Comparing models: the likelihood ratio test</h2>
<p>Another way to compare models is by means of the likelihood ratio test. This test compares the log-likelihood of two models to assess whether they are significantly different. The test follows the <span class="math inline">\(\chi^2\)</span> distribution with degrees of freedom equal to the difference in the number of coefficients between the two models. The test requires a base model and a full model, and the base model must <em>nest</em> within the full model. Nesting in this sense means that full model must be reducible to the base model by setting some coefficients to zero.</p>
<p>For example, consider the utility functions of <code>model2</code>: <span class="math display">\[
\begin{array}{l}
  V_{i\text{Cycle}} = 0 &amp;+&amp; \beta_1\text{time}_{i\text{Cycle}} &amp;+&amp; 0\\
  V_{i\text{Walk}} = \mu_{\text{Walk}} &amp;+&amp; \beta_1\text{time}_{i\text{Walk}} &amp;+&amp; \gamma_{1}\text{age}_{i}\\
  V_{i\text{HSR}} = \mu_{\text{HSR}} &amp;+&amp; \beta_1\text{time}_{i\text{HSR}} &amp;+&amp; \gamma_{2}\text{age}_{i}\\
  V_{i\text{HSR}} = \mu_{\text{Car}} &amp;+&amp; \beta_1\text{time}_{i\text{Car}} &amp;+&amp; \gamma_{3}\text{age}_{i}\\
\end{array}  
\]</span></p>
<p>We can reduce this model to <code>model1</code> by setting <span class="math inline">\(\gamma_{1}=\gamma_{2}=\gamma_{3}=0\)</span>: <span class="math display">\[
\begin{array}{l}
  V_{i\text{Cycle}} = 0 &amp;+&amp; \beta_1\text{time}_{i\text{Cycle}}\\
  V_{i\text{Walk}} = \mu_{\text{Walk}} &amp;+&amp; \beta_1\text{time}_{i\text{Walk}}\\
  V_{i\text{HSR}} = \mu_{\text{HSR}} &amp;+&amp; \beta_1\text{time}_{i\text{HSR}}\\
  V_{i\text{HSR}} = \mu_{\text{Car}} &amp;+&amp; \beta_1\text{time}_{i\text{Car}}\\
\end{array}  
\]</span></p>
<p>In this way, <code>model1</code> “nests” in <code>model2</code>.</p>
<p>In the summary of the models, the likelihood ratio test is reported. See:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model1)</code></pre></div>
<pre><code>## 
## Call:
## mlogit(formula = choice ~ time, data = mc_commute, method = &quot;nr&quot;, 
##     print.level = 0)
## 
## Frequencies of alternatives:
##    Cycle     Walk      HSR      Car 
## 0.034884 0.516715 0.244186 0.204215 
## 
## nr method
## 6 iterations, 0h:0m:0s 
## g&#39;(-H)^-1g = 4.14E-05 
## successive function values within tolerance limits 
## 
## Coefficients :
##                     Estimate  Std. Error z-value  Pr(&gt;|z|)    
## Walk:(intercept)  2.8006e+00  1.5419e-01 18.1632 &lt; 2.2e-16 ***
## HSR:(intercept)   1.7270e+00  1.5493e-01 11.1471 &lt; 2.2e-16 ***
## Car:(intercept)   1.8978e+00  1.6151e-01 11.7506 &lt; 2.2e-16 ***
## time             -9.2134e-06  1.0585e-06 -8.7037 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Log-Likelihood: -1509.6
## McFadden R^2:  0.026441 
## Likelihood ratio test : chisq = 82 (p.value = &lt; 2.22e-16)</code></pre>
<p>In this case, the test is against the null model, that is, a model with no variables at all. This is the least informative of all models.</p>
<p>When two non-null models need to be compared, the <code>lrtest</code> function implements the likelihood ratio test for two inputs, which are two <code>mlogit</code> models, as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lrtest</span>(model1, model2)</code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: choice ~ time
## Model 2: choice ~ time | age
##   #Df  LogLik Df  Chisq Pr(&gt;Chisq)    
## 1   4 -1509.6                         
## 2   7 -1480.4  3 58.512  1.222e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Notice that the number of degrees of freedom (Df) is <span class="math inline">\(3\)</span>: this is because there are three individual-specific parameters in <code>model2</code> that are not present in <code>model1</code>. The null hypothesis of the test is that the log-likelihood of the two models is not different, in other words, that the alternate model is not an improvement over the base model.</p>
<p>In the present case, the very small <span class="math inline">\(p\)</span>-value leads us to reject the null hypothesis, and the conclusion is that <code>model2</code>, which includes age, is a significant improvement over <code>model1</code>, which does not.</p>
</div>
<div id="exercise-3" class="section level2">
<h2><span class="header-section-number">5.12</span> Exercise</h2>
<ol style="list-style-type: decimal">
<li><p>In the example in this chapter we estimated the probabilities of choosing different modes by age setting travel time to the in-sample median. Calculate the probability of choosing the modes as a function of time for ages 17, 20, 23, and 26.</p></li>
<li><p>Estimate a model using formula <code>f3</code> (call it <code>model3</code>). Discuss the output of this model.</p></li>
<li><p>Use the likelihood ratio test to compare <code>model3</code> to <code>model1</code>.</p></li>
<li><p>Can you use the likelihood ratio test to comare <code>model3</code> to <code>model2</code>? Discuss.</p></li>
</ol>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-McFadden2001economic">
<p>McFadden, D. 2001. “Economic Choices.” Journal Article. <em>American Economic Review</em> 91 (3): 351–78. doi:<a href="https://doi.org/10.1257/aer.91.3.351">10.1257/aer.91.3.351</a>.</p>
</div>
<div id="ref-Akerlof1997social">
<p>Akerlof, G. A. 1997. “Social Distance and Social Decisions.” Journal Article. <em>Econometrica</em> 65 (5): 1005–27. <a href="ISI:A1997XT90600001
C:/Papers/Econometrica/Econometrica (1997) 65 (5) 1005-1027.pdf" class="uri">ISI:A1997XT90600001
<div id="ref-Axhausen2005social">
<p>Axhausen, K. 2005. “Social Networks and Travel: Some Hypotheses.” Book Section. In <em>Social Aspects of Sustainable Transport: Transatlantic Perspectives</em>, edited by K. Donaghy, S. Poppelreuter, and G. Rudinger, 90–108. Aldershot: Ashgate Publishing.</p>
</div>
<div id="ref-Paez2007social">
<p>Páez, A., and D. M. Scott. 2007. “Social Influence on Travel Behavior: A Simulation Example of the Decision to Telecommute.” Journal Article. <em>Environment and Planning A</em> 39 (3): 647–65. <a href="ISI:000245598400010
C:/Papers/Environment and Planning A/Environment and Planning A (2007) 39 (3) 647-665.pdf" class="uri">ISI:000245598400010
<div id="ref-Carrasco2007social">
<p>Carrasco, J. A., B. Hogan, B. Wellman, and E. J. Miller. 2008. “Collecting Social Network Data to Study Social Activity-Travel Behavior: An Egocentric Approach.” Journal Article. <em>Environment and Planning B-Planning and Design</em> 35 (6): 961–80. <a href="ISI:000261734600003
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3547633/pdf/nihms429217.pdf" class="uri">ISI:000261734600003
<div id="ref-Axhausen2008social">
<p>Axhausen, K. W. 2008. “Social Networks, Mobility Biographies, and Travel: Survey Challenges.” Journal Article. <em>Environment and Planning B-Planning and Design</em> 35 (6): 981–96. <a href="ISI:000261734600004
C:/Papers/Environment and Planning B/EPB (2008) 35 (6) 981-996.pdf
<div id="ref-Scott2012social">
<p>Scott, D. M., I. Dam, A. Paez, and R. D. Wilton. 2012. “Investigating the Effects of Social Influence on the Choice to Telework.” Journal Article. <em>Environment and Planning A</em> 44 (5): 1016–31. doi:<a href="https://doi.org/10.1068/a43223">10.1068/a43223</a>.</p>
</div>
<div id="ref-Chen2016social">
<p>Chen, Y., and H. S. Mahmassani. 2016. “Use of Social Networking Data to Explore Activity and Destination Choice Behavior in Two Metropolitan Areas.” Journal Article. <em>Transportation Research Record</em>, no. 2566: 71–82. doi:<a href="https://doi.org/10.3141/2566-08">10.3141/2566-08</a>.</p>
</div>
<div id="ref-Dugundji2005discrete">
<p>Dugundji, E. R., and J. L. Walker. 2005. “Discrete Choice with Social and Spatial Network Interdependencies - an Empirical Example Using Mixed Generalized Extreme Value Models with Field and Panel Effects.” Journal Article. <em>Transportation Research Record</em> 1921: 70–78. <a href="ISI:000236203700009
C:/Papers/Transportation Research Record/1921 70-78 Dugundji and Walker.pdf" class="uri">ISI:000236203700009
<div id="ref-Dugundji2013social">
<p>Dugundji, E. R., and L. Gulyas. 2013. “Structure and Emergence in a Nested Logit Model with Social and Spatial Interactions.” Journal Article. <em>Computational and Mathematical Organization Theory</em> 19 (2): 151–203. doi:<a href="https://doi.org/10.1007/s10588-013-9157-y">10.1007/s10588-013-9157-y</a>.</p>
</div>
<div id="ref-Kamargianni2014social">
<p>Kamargianni, M., M. Ben-Akiva, and A. Polydoropoulou. 2014. “Incorporating Social Interaction into Hybrid Choice Models.” Journal Article. <em>Transportation</em> 41 (6): 1263–85. doi:<a href="https://doi.org/10.1007/s11116-014-9550-5">10.1007/s11116-014-9550-5</a>.</p>
</div>
<div id="ref-vandenBerg2009social">
<p>Berg, P. van den, T. A. Arentze, and H. J. P. Timmermans. 2009. “Size and Composition of Ego-Centered Social Networks and Their Effect on Geographic Distance and Contact Frequency.” Journal Article. <em>Transportation Research Record</em>, no. 2135: 1–9. <a href="ISI:000274591300002" class="uri">ISI:000274591300002</a>.</p>
</div>
<div id="ref-Goetzke2011bicycle">
<p>Goetzke, F., and T. Rave. 2011. “Bicycle Use in Germany: Explaining Differences Between Municipalities with Social Network Effects.” Journal Article. <em>Urban Studies</em> 48 (2): 427–37. doi:<a href="https://doi.org/10.1177/0042098009360681">10.1177/0042098009360681</a>.</p>
</div>
<div id="ref-Matous2017social">
<p>Matous, P. 2017. “Complementarity and Substitution Between Physical and Virtual Travel for Instrumental Information Sharing in Remote Rural Regions: A Social Network Approach.” Journal Article. <em>Transportation Research Part a-Policy and Practice</em> 99: 61–79. doi:<a href="https://doi.org/10.1016/j.tra.2017.02.010">10.1016/j.tra.2017.02.010</a>.</p>
</div>
<div id="ref-Benakiva1985discrete">
<p>Ben-Akiva, M., and S. R. Lerman. 1985. <em>Discrete Choice Analysis: Theory and Applications to Travel Demand</em>. Book. Cambridge: The MIT Press.</p>
</div>
<div id="ref-hensher2005applied">
<p>Hensher, David A, John M Rose, and William H Greene. 2005. <em>Applied Choice Analysis: A Primer</em>. Cambridge University Press.</p>
</div>
<div id="ref-Ortuzar2011modelling">
<p>Ortúzar, J. D., and L. G. Willumsen. 2011. <em>Modelling Transport</em>. Book. Vol. Fourth Edition. New York: Wiley.</p>
</div>
<div id="ref-Train2009discrete">
<p>Train, K. 2009. <em>Discrete Choice Methods with Simulation</em>. Book. 2nd Edition. Cambridge: Cambridge University Press.</p>
</div>
<div id="ref-Whalen2013">
<p>Whalen, Kate E., Antonio Páez, and Juan A. Carrasco. 2013. “Mode Choice of University Students Commuting to School and the Role of Active Travel.” Journal Article. <em>Journal of Transport Geography</em> 31: 132–42. doi:<a href="https://doi.org/http://dx.doi.org/10.1016/j.jtrangeo.2013.06.008">http://dx.doi.org/10.1016/j.jtrangeo.2013.06.008</a>.</p>
</div>
<div id="ref-Henningsen2011maxlik">
<p>Henningsen, Arne, and Ott Toomet. 2011. “MaxLik: A Package for Maximum Likelihood Estimation in R.” <em>Computational Statistics</em> 26 (3): 443–58. doi:<a href="https://doi.org/10.1007/s00180-010-0217-1">10.1007/s00180-010-0217-1</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter-3.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter-5.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-Practical-Matters.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
